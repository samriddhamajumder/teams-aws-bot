2025-05-06 23:33:44,022 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-06 23:33:44,022 INFO:[33mPress CTRL+C to quit[0m
2025-05-06 23:33:44,025 INFO: * Restarting with stat
2025-05-06 23:33:51,656 WARNING: * Debugger is active!
2025-05-06 23:33:51,660 INFO: * Debugger PIN: 109-785-705
2025-05-06 23:34:23,323 INFO:127.0.0.1 - - [06/May/2025 23:34:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:34:31,003 INFO:127.0.0.1 - - [06/May/2025 23:34:31] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:39:06,977 INFO:127.0.0.1 - - [06/May/2025 23:39:06] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:39:38,811 INFO:127.0.0.1 - - [06/May/2025 23:39:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:47:10,714 INFO:127.0.0.1 - - [06/May/2025 23:47:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:47:46,344 INFO:127.0.0.1 - - [06/May/2025 23:47:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:48:12,487 INFO:127.0.0.1 - - [06/May/2025 23:48:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-06 23:55:35,161 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-06 23:55:36,876 INFO: * Restarting with stat
2025-05-06 23:55:47,885 WARNING: * Debugger is active!
2025-05-06 23:55:47,889 INFO: * Debugger PIN: 109-785-705
2025-05-06 23:56:18,996 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-06 23:56:19,703 INFO: * Restarting with stat
2025-05-06 23:56:27,733 WARNING: * Debugger is active!
2025-05-06 23:56:27,736 INFO: * Debugger PIN: 109-785-705
2025-05-06 23:58:41,015 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-06 23:58:41,749 INFO: * Restarting with stat
2025-05-06 23:58:50,028 WARNING: * Debugger is active!
2025-05-06 23:58:50,032 INFO: * Debugger PIN: 109-785-705
2025-05-06 23:59:41,934 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-06 23:59:42,698 INFO: * Restarting with stat
2025-05-06 23:59:52,497 WARNING: * Debugger is active!
2025-05-06 23:59:52,500 INFO: * Debugger PIN: 109-785-705
2025-05-07 00:09:03,758 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\aws_crew_tools\\vpc.py', reloading
2025-05-07 00:09:04,750 INFO: * Restarting with stat
2025-05-07 00:09:59,938 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 00:09:59,938 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 00:09:59,940 INFO: * Restarting with stat
2025-05-07 00:10:07,780 WARNING: * Debugger is active!
2025-05-07 00:10:07,783 INFO: * Debugger PIN: 109-785-705
2025-05-07 00:12:54,203 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:13:09,682 INFO:127.0.0.1 - - [07/May/2025 00:13:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 00:14:20,763 INFO:127.0.0.1 - - [07/May/2025 00:14:20] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 00:15:26,291 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:15:26,311 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:15:26,900 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:15:27,069 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:15:27,101 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:15:27,132 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:15:27,315 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:18:14,208 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:18:14,212 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:18:14,225 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:18:14,309 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:18:14,411 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:22:30,637 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:22:30,648 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:22:30,661 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:22:30,736 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:22:30,833 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:26:42,726 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:26:42,735 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:26:42,848 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:26:42,903 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:27:13,324 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:30:29,781 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:30:29,824 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:30:29,930 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:30:29,993 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:30:31,238 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:34:30,336 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:34:30,356 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:34:30,432 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:34:30,494 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:34:31,765 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:38:24,540 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:38:24,556 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:38:24,566 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:38:24,644 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:38:24,720 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 00:41:28,907 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-07 00:42:40,212 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:42:40,237 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:42:40,316 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-07 00:42:40,331 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:46:00,589 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:46:00,592 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:46:00,683 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-07 00:46:00,692 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 00:47:12,728 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 00:47:12,743 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 00:47:12,749 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-07 00:47:12,805 ERROR:Error processing activity: cannot schedule new futures after interpreter shutdown
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 174, in run_pipeline
    return await self._middleware.receive_activity_with_status(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 69, in receive_activity_with_status
    return await self.receive_activity_internal(context, callback)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 79, in receive_activity_internal
    return await callback(context)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\activity_handler.py", line 70, in on_turn
    await self.on_message_activity(turn_context)
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 109, in on_message_activity
    await turn_context.send_activity(response)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 68, in messages
    response = await adapter.process_activity(activity, auth_header, bot.on_turn)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 445, in process_activity
    return await self.process_activity_with_identity(activity, identity, logic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 487, in process_activity_with_identity
    await self.run_pipeline(context, logic)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 179, in run_pipeline
    await self.on_turn_error(context, error)
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 49, in on_error
    await context.send_activity("Sorry, something went wrong processing your request.")
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
2025-05-07 00:47:13,000 INFO:127.0.0.1 - - [07/May/2025 00:47:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 500 -
2025-05-07 01:38:06,370 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 01:38:06,370 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 01:38:06,373 INFO: * Restarting with stat
2025-05-07 01:38:14,183 WARNING: * Debugger is active!
2025-05-07 01:38:14,188 INFO: * Debugger PIN: 109-785-705
2025-05-07 01:38:26,888 INFO:127.0.0.1 - - [07/May/2025 01:38:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 01:38:31,549 INFO:127.0.0.1 - - [07/May/2025 01:38:31] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 01:40:40,159 INFO:127.0.0.1 - - [07/May/2025 01:40:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 01:50:43,729 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 01:50:43,729 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 01:50:43,732 INFO: * Restarting with stat
2025-05-07 01:50:51,847 WARNING: * Debugger is active!
2025-05-07 01:50:51,852 INFO: * Debugger PIN: 109-785-705
2025-05-07 01:51:04,400 INFO:127.0.0.1 - - [07/May/2025 01:51:04] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 01:51:53,311 INFO:127.0.0.1 - - [07/May/2025 01:51:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:04:22,870 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 15:04:22,870 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 15:04:22,874 INFO: * Restarting with stat
2025-05-07 15:04:39,904 WARNING: * Debugger is active!
2025-05-07 15:04:39,909 INFO: * Debugger PIN: 379-540-163
2025-05-07 15:08:22,710 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 15:08:22,710 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 15:08:22,714 INFO: * Restarting with stat
2025-05-07 15:08:39,976 WARNING: * Debugger is active!
2025-05-07 15:08:40,017 INFO: * Debugger PIN: 379-540-163
2025-05-07 15:13:22,220 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 15:13:22,220 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 15:13:22,225 INFO: * Restarting with stat
2025-05-07 15:13:38,452 WARNING: * Debugger is active!
2025-05-07 15:13:38,500 INFO: * Debugger PIN: 379-540-163
2025-05-07 15:14:14,745 INFO:127.0.0.1 - - [07/May/2025 15:14:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:14:20,638 INFO:127.0.0.1 - - [07/May/2025 15:14:20] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:15:41,870 INFO:127.0.0.1 - - [07/May/2025 15:15:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:35:51,619 INFO:127.0.0.1 - - [07/May/2025 15:35:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:36:12,792 INFO:127.0.0.1 - - [07/May/2025 15:36:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:37:22,658 INFO:127.0.0.1 - - [07/May/2025 15:37:22] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:37:50,409 INFO:127.0.0.1 - - [07/May/2025 15:37:50] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 15:38:11,442 INFO:127.0.0.1 - - [07/May/2025 15:38:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 18:58:15,902 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 18:58:15,903 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 18:58:15,904 INFO: * Restarting with stat
2025-05-07 18:58:24,333 WARNING: * Debugger is active!
2025-05-07 18:58:24,338 INFO: * Debugger PIN: 379-540-163
2025-05-07 18:58:33,342 INFO:127.0.0.1 - - [07/May/2025 18:58:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 18:58:38,719 INFO:127.0.0.1 - - [07/May/2025 18:58:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 19:03:22,985 INFO:127.0.0.1 - - [07/May/2025 19:03:22] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 19:04:16,772 INFO:127.0.0.1 - - [07/May/2025 19:04:16] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 19:05:54,746 INFO:127.0.0.1 - - [07/May/2025 19:05:54] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 19:06:52,392 INFO:127.0.0.1 - - [07/May/2025 19:06:52] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 20:26:45,556 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 20:26:45,556 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 20:26:45,564 INFO: * Restarting with stat
2025-05-07 20:26:53,573 WARNING: * Debugger is active!
2025-05-07 20:26:53,589 INFO: * Debugger PIN: 379-540-163
2025-05-07 20:27:04,787 INFO:127.0.0.1 - - [07/May/2025 20:27:04] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 20:27:21,621 INFO:127.0.0.1 - - [07/May/2025 20:27:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 20:27:30,918 INFO:127.0.0.1 - - [07/May/2025 20:27:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 20:27:40,117 INFO:127.0.0.1 - - [07/May/2025 20:27:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:08:32,380 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 21:08:32,380 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 21:08:32,383 INFO: * Restarting with stat
2025-05-07 21:08:40,480 WARNING: * Debugger is active!
2025-05-07 21:08:40,483 INFO: * Debugger PIN: 379-540-163
2025-05-07 21:08:54,555 INFO:127.0.0.1 - - [07/May/2025 21:08:54] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:08:56,693 INFO:127.0.0.1 - - [07/May/2025 21:08:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:10:17,954 INFO:127.0.0.1 - - [07/May/2025 21:10:17] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:11:11,537 INFO:127.0.0.1 - - [07/May/2025 21:11:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:11:45,340 INFO:127.0.0.1 - - [07/May/2025 21:11:45] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:12:18,311 INFO:127.0.0.1 - - [07/May/2025 21:12:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:12:45,037 INFO:127.0.0.1 - - [07/May/2025 21:12:45] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:12:59,273 INFO:127.0.0.1 - - [07/May/2025 21:12:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:13:14,320 INFO:127.0.0.1 - - [07/May/2025 21:13:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:37:39,367 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 21:37:39,367 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 21:37:39,373 INFO: * Restarting with stat
2025-05-07 21:37:47,526 WARNING: * Debugger is active!
2025-05-07 21:37:47,543 INFO: * Debugger PIN: 379-540-163
2025-05-07 21:37:54,480 INFO:127.0.0.1 - - [07/May/2025 21:37:54] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:38:00,201 INFO:127.0.0.1 - - [07/May/2025 21:38:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:38:41,218 INFO:127.0.0.1 - - [07/May/2025 21:38:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:39:14,227 INFO:127.0.0.1 - - [07/May/2025 21:39:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:39:34,011 INFO:127.0.0.1 - - [07/May/2025 21:39:34] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:46:46,440 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 21:46:46,440 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 21:46:46,441 INFO: * Restarting with stat
2025-05-07 21:46:56,202 WARNING: * Debugger is active!
2025-05-07 21:46:56,204 INFO: * Debugger PIN: 379-540-163
2025-05-07 21:47:17,212 INFO:127.0.0.1 - - [07/May/2025 21:47:17] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:48:00,532 INFO:127.0.0.1 - - [07/May/2025 21:48:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:48:11,320 INFO:127.0.0.1 - - [07/May/2025 21:48:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 21:48:22,290 INFO:127.0.0.1 - - [07/May/2025 21:48:22] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:00:25,512 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-07 22:00:26,292 INFO: * Restarting with stat
2025-05-07 22:00:35,037 WARNING: * Debugger is active!
2025-05-07 22:00:35,040 INFO: * Debugger PIN: 379-540-163
2025-05-07 22:00:47,157 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 22:00:47,157 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 22:00:47,159 INFO: * Restarting with stat
2025-05-07 22:00:55,368 WARNING: * Debugger is active!
2025-05-07 22:00:55,372 INFO: * Debugger PIN: 379-540-163
2025-05-07 22:01:00,017 INFO:127.0.0.1 - - [07/May/2025 22:01:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:01:46,927 INFO:127.0.0.1 - - [07/May/2025 22:01:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:02:23,935 INFO:127.0.0.1 - - [07/May/2025 22:02:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:02:30,112 INFO:127.0.0.1 - - [07/May/2025 22:02:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:06:55,656 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-07 22:06:56,388 INFO: * Restarting with stat
2025-05-07 22:07:04,798 WARNING: * Debugger is active!
2025-05-07 22:07:04,799 INFO: * Debugger PIN: 379-540-163
2025-05-07 22:08:34,153 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 22:08:34,153 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 22:08:34,153 INFO: * Restarting with stat
2025-05-07 22:08:43,028 WARNING: * Debugger is active!
2025-05-07 22:08:43,032 INFO: * Debugger PIN: 379-540-163
2025-05-07 22:09:28,708 INFO:127.0.0.1 - - [07/May/2025 22:09:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:10:02,322 INFO:127.0.0.1 - - [07/May/2025 22:10:02] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:10:15,368 INFO:127.0.0.1 - - [07/May/2025 22:10:15] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:41:14,004 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 22:41:14,004 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 22:41:14,004 INFO: * Restarting with stat
2025-05-07 22:41:22,668 WARNING: * Debugger is active!
2025-05-07 22:41:22,668 INFO: * Debugger PIN: 379-540-163
2025-05-07 22:41:30,288 INFO:127.0.0.1 - - [07/May/2025 22:41:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:41:34,161 INFO:127.0.0.1 - - [07/May/2025 22:41:34] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:41:56,468 INFO:127.0.0.1 - - [07/May/2025 22:41:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:42:06,484 INFO:127.0.0.1 - - [07/May/2025 22:42:06] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:42:12,720 INFO:127.0.0.1 - - [07/May/2025 22:42:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:42:55,570 INFO:127.0.0.1 - - [07/May/2025 22:42:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:43:12,372 INFO:127.0.0.1 - - [07/May/2025 22:43:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 22:43:37,690 INFO:127.0.0.1 - - [07/May/2025 22:43:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:14:40,738 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-07 23:14:41,757 INFO: * Restarting with stat
2025-05-07 23:14:52,465 WARNING: * Debugger is active!
2025-05-07 23:14:52,467 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:15:36,821 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 23:15:36,821 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 23:15:36,823 INFO: * Restarting with stat
2025-05-07 23:15:45,438 WARNING: * Debugger is active!
2025-05-07 23:15:45,444 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:15:50,195 INFO:127.0.0.1 - - [07/May/2025 23:15:50] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:15:52,883 INFO:127.0.0.1 - - [07/May/2025 23:15:52] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:16:10,493 INFO:127.0.0.1 - - [07/May/2025 23:16:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:16:28,703 INFO:127.0.0.1 - - [07/May/2025 23:16:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:24:05,218 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-07 23:24:05,922 INFO: * Restarting with stat
2025-05-07 23:24:14,425 WARNING: * Debugger is active!
2025-05-07 23:24:14,428 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:29:22,048 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-07 23:29:22,768 INFO: * Restarting with stat
2025-05-07 23:29:31,280 WARNING: * Debugger is active!
2025-05-07 23:29:31,283 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:34:06,199 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-07 23:34:06,989 INFO: * Restarting with stat
2025-05-07 23:34:15,891 WARNING: * Debugger is active!
2025-05-07 23:34:15,891 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:35:07,792 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 23:35:07,792 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 23:35:07,792 INFO: * Restarting with stat
2025-05-07 23:35:16,470 WARNING: * Debugger is active!
2025-05-07 23:35:16,475 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:35:19,436 INFO:127.0.0.1 - - [07/May/2025 23:35:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:35:23,829 INFO:127.0.0.1 - - [07/May/2025 23:35:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:36:40,628 INFO:[TeamsBot] Proceeding to create VPC with name: radha
2025-05-07 23:37:03,294 INFO:[TeamsBot] Proceeding to create VPC with name: radha
2025-05-07 23:38:40,509 INFO:127.0.0.1 - - [07/May/2025 23:38:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:39:33,348 INFO:127.0.0.1 - - [07/May/2025 23:39:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:42:51,159 INFO:127.0.0.1 - - [07/May/2025 23:42:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:43:41,232 INFO:127.0.0.1 - - [07/May/2025 23:43:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:43:49,001 INFO:127.0.0.1 - - [07/May/2025 23:43:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:43:55,250 INFO:127.0.0.1 - - [07/May/2025 23:43:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:44:04,239 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:44:28,528 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:44:39,521 INFO:127.0.0.1 - - [07/May/2025 23:44:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:44:49,594 INFO:127.0.0.1 - - [07/May/2025 23:44:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:45:21,249 INFO:127.0.0.1 - - [07/May/2025 23:45:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:45:26,122 INFO:127.0.0.1 - - [07/May/2025 23:45:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:45:30,271 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:46:40,956 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:46:56,691 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:47:13,946 INFO:127.0.0.1 - - [07/May/2025 23:47:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:47:15,658 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 23:47:15,696 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 23:47:15,779 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 23:47:15,792 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 23:47:16,746 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:47:16,801 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 23:47:16,914 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 23:47:25,935 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:48:38,397 INFO:127.0.0.1 - - [07/May/2025 23:48:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:48:43,436 INFO:127.0.0.1 - - [07/May/2025 23:48:43] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:48:44,003 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 23:48:44,003 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 23:48:44,023 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:48:44,091 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 23:48:44,188 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-07 23:49:35,437 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-07 23:49:35,444 INFO:Wrapper: Completed Call, calling success_handler
2025-05-07 23:49:35,502 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-07 23:49:35,506 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-07 23:50:59,797 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 23:50:59,797 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 23:50:59,799 INFO: * Restarting with stat
2025-05-07 23:51:08,407 WARNING: * Debugger is active!
2025-05-07 23:51:08,414 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:51:18,918 INFO:127.0.0.1 - - [07/May/2025 23:51:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:51:23,367 INFO:127.0.0.1 - - [07/May/2025 23:51:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:51:29,664 INFO:127.0.0.1 - - [07/May/2025 23:51:29] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:51:40,677 INFO:127.0.0.1 - - [07/May/2025 23:51:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:54:10,604 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-07 23:54:11,360 INFO: * Restarting with stat
2025-05-07 23:55:13,450 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 23:55:13,450 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 23:55:13,452 INFO: * Restarting with stat
2025-05-07 23:55:21,900 WARNING: * Debugger is active!
2025-05-07 23:55:21,900 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:56:11,812 INFO:127.0.0.1 - - [07/May/2025 23:56:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:57:40,590 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-07 23:57:41,382 INFO: * Restarting with stat
2025-05-07 23:57:49,961 WARNING: * Debugger is active!
2025-05-07 23:57:49,966 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:58:01,405 INFO:127.0.0.1 - - [07/May/2025 23:58:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:58:16,442 INFO:127.0.0.1 - - [07/May/2025 23:58:16] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:58:51,905 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-07 23:58:51,905 INFO:[33mPress CTRL+C to quit[0m
2025-05-07 23:58:51,907 INFO: * Restarting with stat
2025-05-07 23:59:00,344 WARNING: * Debugger is active!
2025-05-07 23:59:00,345 INFO: * Debugger PIN: 379-540-163
2025-05-07 23:59:07,476 INFO:127.0.0.1 - - [07/May/2025 23:59:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:59:18,892 INFO:127.0.0.1 - - [07/May/2025 23:59:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:59:26,257 INFO:127.0.0.1 - - [07/May/2025 23:59:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-07 23:59:58,617 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:00:42,579 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:01:00,563 INFO:127.0.0.1 - - [08/May/2025 00:01:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:01:12,498 INFO:127.0.0.1 - - [08/May/2025 00:01:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:01:33,687 INFO:127.0.0.1 - - [08/May/2025 00:01:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:01:35,209 INFO:127.0.0.1 - - [08/May/2025 00:01:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:01:50,360 INFO:127.0.0.1 - - [08/May/2025 00:01:50] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:02:14,970 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:02:14,980 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:02:15,047 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:02:15,047 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:02:15,093 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:02:15,159 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:02:15,444 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:03:09,468 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:03:09,470 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:03:09,478 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:03:09,543 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:03:09,609 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:03:44,339 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\crew_handler.py', reloading
2025-05-08 00:04:58,795 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 00:04:58,795 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 00:04:58,796 INFO: * Restarting with stat
2025-05-08 00:05:07,255 WARNING: * Debugger is active!
2025-05-08 00:05:07,258 INFO: * Debugger PIN: 379-540-163
2025-05-08 00:05:12,656 INFO:127.0.0.1 - - [08/May/2025 00:05:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:05:26,749 INFO:127.0.0.1 - - [08/May/2025 00:05:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:05:33,751 INFO:127.0.0.1 - - [08/May/2025 00:05:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:06:49,789 INFO:127.0.0.1 - - [08/May/2025 00:06:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:06:56,963 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:07:43,227 INFO:127.0.0.1 - - [08/May/2025 00:07:43] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:07:51,409 INFO:127.0.0.1 - - [08/May/2025 00:07:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:08:00,703 INFO:127.0.0.1 - - [08/May/2025 00:08:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:08:12,181 INFO:127.0.0.1 - - [08/May/2025 00:08:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:08:20,848 INFO:127.0.0.1 - - [08/May/2025 00:08:20] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:08:37,387 INFO:127.0.0.1 - - [08/May/2025 00:08:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:09:06,188 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:09:06,192 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:09:06,250 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:09:06,262 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:09:06,288 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:09:06,322 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:09:06,398 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:09:14,026 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 00:09:33,143 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 00:09:33,143 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 00:09:33,145 INFO: * Restarting with stat
2025-05-08 00:09:41,269 WARNING: * Debugger is active!
2025-05-08 00:09:41,269 INFO: * Debugger PIN: 379-540-163
2025-05-08 00:09:51,594 INFO:127.0.0.1 - - [08/May/2025 00:09:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:09:53,935 INFO:127.0.0.1 - - [08/May/2025 00:09:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:10:08,196 INFO:127.0.0.1 - - [08/May/2025 00:10:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:10:20,212 INFO:127.0.0.1 - - [08/May/2025 00:10:20] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:10:27,254 INFO:127.0.0.1 - - [08/May/2025 00:10:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:10:35,263 INFO:127.0.0.1 - - [08/May/2025 00:10:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:11:10,757 INFO:127.0.0.1 - - [08/May/2025 00:11:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:11:14,117 INFO:127.0.0.1 - - [08/May/2025 00:11:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:14:03,860 INFO:127.0.0.1 - - [08/May/2025 00:14:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:14:34,842 INFO:127.0.0.1 - - [08/May/2025 00:14:34] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:15:10,716 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:17:41,818 INFO:127.0.0.1 - - [08/May/2025 00:17:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:18:38,633 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:18:38,636 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:18:39,129 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:18:39,135 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:18:39,163 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:18:39,206 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:18:39,264 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:19:05,085 INFO:[TeamsBot] Creating EC2 with: {'self': <bot.teams_bot.TeamsBot object at 0x000001F0D97CAF90>, 'data': {'action': 'create_ec2', 'Name': 'sam', 'InstanceType': 't2.micro', 'AmiId': 'default', 'KeyPairName': 'samaee', 'SecurityGroupId': 'sg-059b5407f7675e470', 'SubnetId': 'subnet-0ea3ee8000ab75e32', 'IamRole': 'SSMAgentRole', 'EBSSize': '8', 'BootstrapScript': 'None', 'CustomTags': 'sa=sa', 'PublicIp': 'false', 'ElasticIp': 'false', 'TerminationProtection': 'false'}, 'turn_context': <botbuilder.core.turn_context.TurnContext object at 0x000001F0DD9396D0>, 'name': 'sam', 'instance_type': 't2.micro', 'ami_id': 'default', 'key_name': 'samaee', 'security_group_id': 'sg-059b5407f7675e470', 'subnet_id': 'subnet-0ea3ee8000ab75e32', 'iam_role': 'SSMAgentRole', 'ebs_size': 8, 'bootstrap_script_name': 'None', 'public_ip': False, 'elastic_ip': False, 'termination_protection': False, 'custom_tags': {'sa': 'sa'}, 'pair': 'sa=sa', 'k': 'sa', 'v': 'sa'}
2025-05-08 00:19:10,013 WARNING:Private subnet detected: subnet-0ea3ee8000ab75e32. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 00:19:12,743 ERROR:\u274c EC2 Creation Failed
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\aws_crew_tools\ec2.py", line 177, in create_instance
    response = ec2_client.run_instances(**instance_params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\client.py", line 570, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\context.py", line 123, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\client.py", line 1031, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (InvalidParameter) when calling the RunInstances operation: Security group sg-059b5407f7675e470 and subnet subnet-0ea3ee8000ab75e32 belong to different networks.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 187, in _handle_ec2_creation
    result = create_instance(
             ^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\aws_crew_tools\ec2.py", line 211, in create_instance
    raise RuntimeError(f"Failed to create EC2 instance: {e}")
RuntimeError: Failed to create EC2 instance: An error occurred (InvalidParameter) when calling the RunInstances operation: Security group sg-059b5407f7675e470 and subnet subnet-0ea3ee8000ab75e32 belong to different networks.
2025-05-08 00:19:13,145 INFO:127.0.0.1 - - [08/May/2025 00:19:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:19:54,455 INFO:[TeamsBot] Creating EC2 with: {'self': <bot.teams_bot.TeamsBot object at 0x000001F0D97CAF90>, 'data': {'action': 'create_ec2', 'Name': 'sam', 'InstanceType': 't2.micro', 'AmiId': 'default', 'KeyPairName': 'samaee', 'SecurityGroupId': 'sg-03f5102c878a7cc1a', 'SubnetId': 'subnet-099d81908aaa7fe63', 'IamRole': 'SSMAgentRole', 'EBSSize': '8', 'BootstrapScript': 'None', 'CustomTags': 'sa=sa', 'PublicIp': 'false', 'ElasticIp': 'false', 'TerminationProtection': 'false'}, 'turn_context': <botbuilder.core.turn_context.TurnContext object at 0x000001F0DE18BD10>, 'name': 'sam', 'instance_type': 't2.micro', 'ami_id': 'default', 'key_name': 'samaee', 'security_group_id': 'sg-03f5102c878a7cc1a', 'subnet_id': 'subnet-099d81908aaa7fe63', 'iam_role': 'SSMAgentRole', 'ebs_size': 8, 'bootstrap_script_name': 'None', 'public_ip': False, 'elastic_ip': False, 'termination_protection': False, 'custom_tags': {'sa': 'sa'}, 'pair': 'sa=sa', 'k': 'sa', 'v': 'sa'}
2025-05-08 00:20:00,590 ERROR:\u274c EC2 Creation Failed
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\aws_crew_tools\ec2.py", line 177, in create_instance
    response = ec2_client.run_instances(**instance_params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\client.py", line 570, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\context.py", line 123, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\client.py", line 1031, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (InvalidParameter) when calling the RunInstances operation: Security group sg-03f5102c878a7cc1a and subnet subnet-099d81908aaa7fe63 belong to different networks.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 187, in _handle_ec2_creation
    result = create_instance(
             ^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\aws_crew_tools\ec2.py", line 211, in create_instance
    raise RuntimeError(f"Failed to create EC2 instance: {e}")
RuntimeError: Failed to create EC2 instance: An error occurred (InvalidParameter) when calling the RunInstances operation: Security group sg-03f5102c878a7cc1a and subnet subnet-099d81908aaa7fe63 belong to different networks.
2025-05-08 00:20:00,914 INFO:127.0.0.1 - - [08/May/2025 00:20:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:20:16,824 INFO:[TeamsBot] Creating EC2 with: {'self': <bot.teams_bot.TeamsBot object at 0x000001F0D97CAF90>, 'data': {'action': 'create_ec2', 'Name': 'sam', 'InstanceType': 't2.micro', 'AmiId': 'default', 'KeyPairName': 'samaee', 'SecurityGroupId': 'sg-06fef524ce8ca1157', 'SubnetId': 'subnet-099d81908aaa7fe63', 'IamRole': 'SSMAgentRole', 'EBSSize': '8', 'BootstrapScript': 'None', 'CustomTags': 'sa=sa', 'PublicIp': 'false', 'ElasticIp': 'false', 'TerminationProtection': 'false'}, 'turn_context': <botbuilder.core.turn_context.TurnContext object at 0x000001F0DE1D1A10>, 'name': 'sam', 'instance_type': 't2.micro', 'ami_id': 'default', 'key_name': 'samaee', 'security_group_id': 'sg-06fef524ce8ca1157', 'subnet_id': 'subnet-099d81908aaa7fe63', 'iam_role': 'SSMAgentRole', 'ebs_size': 8, 'bootstrap_script_name': 'None', 'public_ip': False, 'elastic_ip': False, 'termination_protection': False, 'custom_tags': {'sa': 'sa'}, 'pair': 'sa=sa', 'k': 'sa', 'v': 'sa'}
2025-05-08 00:20:23,949 ERROR:\u274c EC2 Creation Failed
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\aws_crew_tools\ec2.py", line 177, in create_instance
    response = ec2_client.run_instances(**instance_params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\client.py", line 570, in _api_call
    return self._make_api_call(operation_name, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\context.py", line 123, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botocore\client.py", line 1031, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (InvalidParameter) when calling the RunInstances operation: Security group sg-06fef524ce8ca1157 and subnet subnet-099d81908aaa7fe63 belong to different networks.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 187, in _handle_ec2_creation
    result = create_instance(
             ^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\aws_crew_tools\ec2.py", line 211, in create_instance
    raise RuntimeError(f"Failed to create EC2 instance: {e}")
RuntimeError: Failed to create EC2 instance: An error occurred (InvalidParameter) when calling the RunInstances operation: Security group sg-06fef524ce8ca1157 and subnet subnet-099d81908aaa7fe63 belong to different networks.
2025-05-08 00:20:24,289 INFO:127.0.0.1 - - [08/May/2025 00:20:24] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:20:40,230 INFO:[TeamsBot] Creating EC2 with: {'self': <bot.teams_bot.TeamsBot object at 0x000001F0D97CAF90>, 'data': {'action': 'create_ec2', 'Name': 'sam', 'InstanceType': 't2.micro', 'AmiId': 'default', 'KeyPairName': 'samaee', 'SecurityGroupId': 'sg-059b5407f7675e470', 'SubnetId': 'subnet-099d81908aaa7fe63', 'IamRole': 'SSMAgentRole', 'EBSSize': '8', 'BootstrapScript': 'None', 'CustomTags': 'sa=sa', 'PublicIp': 'false', 'ElasticIp': 'false', 'TerminationProtection': 'false'}, 'turn_context': <botbuilder.core.turn_context.TurnContext object at 0x000001F0DD8A58D0>, 'name': 'sam', 'instance_type': 't2.micro', 'ami_id': 'default', 'key_name': 'samaee', 'security_group_id': 'sg-059b5407f7675e470', 'subnet_id': 'subnet-099d81908aaa7fe63', 'iam_role': 'SSMAgentRole', 'ebs_size': 8, 'bootstrap_script_name': 'None', 'public_ip': False, 'elastic_ip': False, 'termination_protection': False, 'custom_tags': {'sa': 'sa'}, 'pair': 'sa=sa', 'k': 'sa', 'v': 'sa'}
2025-05-08 00:20:48,096 INFO:127.0.0.1 - - [08/May/2025 00:20:48] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:22:25,857 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:22:25,866 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:22:25,889 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:22:25,955 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:22:26,076 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:22:30,225 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:26:30,195 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:26:30,205 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:26:30,288 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:26:30,371 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:26:51,014 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:28:54,428 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 00:28:54,428 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 00:28:54,489 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:28:54,575 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 00:28:55,722 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 00:28:56,617 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 00:29:47,828 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 00:29:47,829 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 00:29:47,831 INFO: * Restarting with stat
2025-05-08 00:29:56,306 WARNING: * Debugger is active!
2025-05-08 00:29:56,320 INFO: * Debugger PIN: 379-540-163
2025-05-08 00:30:15,839 INFO:127.0.0.1 - - [08/May/2025 00:30:15] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:30:23,152 INFO:127.0.0.1 - - [08/May/2025 00:30:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:30:28,760 INFO:127.0.0.1 - - [08/May/2025 00:30:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:30:37,347 INFO:127.0.0.1 - - [08/May/2025 00:30:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:30:40,420 INFO:127.0.0.1 - - [08/May/2025 00:30:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:30:55,428 INFO:127.0.0.1 - - [08/May/2025 00:30:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 00:30:57,730 INFO:127.0.0.1 - - [08/May/2025 00:30:57] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:10:07,235 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 14:10:07,235 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 14:10:07,235 INFO: * Restarting with stat
2025-05-08 14:10:15,985 WARNING: * Debugger is active!
2025-05-08 14:10:15,985 INFO: * Debugger PIN: 379-540-163
2025-05-08 14:10:32,299 INFO:127.0.0.1 - - [08/May/2025 14:10:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:10:40,558 INFO:127.0.0.1 - - [08/May/2025 14:10:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:12:09,009 INFO:127.0.0.1 - - [08/May/2025 14:12:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:13:21,529 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:13:44,282 INFO:127.0.0.1 - - [08/May/2025 14:13:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:14:09,968 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:15:20,473 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:15:20,518 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:15:20,610 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:20,623 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:20,736 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:20,818 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:21,668 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:15:31,926 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:15:31,928 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:15:31,953 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:15:32,038 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:32,141 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:57,989 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:15:57,995 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:15:58,120 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:58,252 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:15:58,353 INFO:127.0.0.1 - - [08/May/2025 14:15:58] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:16:34,452 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:16:34,454 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:16:34,593 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:16:34,752 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:16:35,469 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:22:58,503 INFO:127.0.0.1 - - [08/May/2025 14:22:58] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:23:11,011 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:23:32,465 INFO:127.0.0.1 - - [08/May/2025 14:23:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:25:02,866 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:25:02,866 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:25:02,888 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:25:03,773 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:25:03,874 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:25:46,987 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:25:46,987 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:25:47,018 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:25:47,119 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:25:47,253 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:26:35,791 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out after 600.0 seconds.
2025-05-08 14:26:36,109 INFO:127.0.0.1 - - [08/May/2025 14:26:36] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:27:44,750 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:27:44,750 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:27:44,771 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 14:27:44,869 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:27:44,994 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:29:41,808 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 14:29:41,810 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 14:29:41,931 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:29:42,030 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 14:29:42,138 INFO:127.0.0.1 - - [08/May/2025 14:29:42] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:39:59,303 INFO:127.0.0.1 - - [08/May/2025 14:39:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 14:43:00,039 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 14:43:00,863 INFO: * Restarting with stat
2025-05-08 14:43:10,773 WARNING: * Debugger is active!
2025-05-08 14:43:10,775 INFO: * Debugger PIN: 379-540-163
2025-05-08 14:51:30,232 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 14:51:30,942 INFO: * Restarting with stat
2025-05-08 14:51:39,088 WARNING: * Debugger is active!
2025-05-08 14:51:39,088 INFO: * Debugger PIN: 379-540-163
2025-05-08 14:52:49,088 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-08 14:52:49,760 INFO: * Restarting with stat
2025-05-08 14:52:57,880 WARNING: * Debugger is active!
2025-05-08 14:52:57,891 INFO: * Debugger PIN: 379-540-163
2025-05-08 14:54:03,365 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-08 14:54:04,104 INFO: * Restarting with stat
2025-05-08 14:54:12,702 WARNING: * Debugger is active!
2025-05-08 14:54:12,707 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:02:05,581 INFO:127.0.0.1 - - [08/May/2025 15:02:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:02:14,931 INFO:127.0.0.1 - - [08/May/2025 15:02:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:03:24,557 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 15:03:24,557 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 15:03:24,557 INFO: * Restarting with stat
2025-05-08 15:03:32,612 WARNING: * Debugger is active!
2025-05-08 15:03:32,615 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:03:38,694 INFO:127.0.0.1 - - [08/May/2025 15:03:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:03:49,423 INFO:127.0.0.1 - - [08/May/2025 15:03:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:04:53,259 INFO:127.0.0.1 - - [08/May/2025 15:04:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:05:07,839 INFO:127.0.0.1 - - [08/May/2025 15:05:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:05:44,759 INFO:127.0.0.1 - - [08/May/2025 15:05:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:08:30,742 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 15:08:31,468 INFO: * Restarting with stat
2025-05-08 15:08:39,703 WARNING: * Debugger is active!
2025-05-08 15:08:39,703 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:09:12,061 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 15:09:12,061 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 15:09:12,065 INFO: * Restarting with stat
2025-05-08 15:09:20,168 WARNING: * Debugger is active!
2025-05-08 15:09:20,180 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:09:39,054 INFO:127.0.0.1 - - [08/May/2025 15:09:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:09:46,298 INFO:[UserMessage] Received: upload file
2025-05-08 15:09:46,299 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 15:09:47,984 INFO:127.0.0.1 - - [08/May/2025 15:09:47] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:10:12,785 INFO:[UserMessage] Received: upload file to s3
2025-05-08 15:10:12,785 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 15:10:14,302 INFO:127.0.0.1 - - [08/May/2025 15:10:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:13:14,729 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-08 15:13:15,410 INFO: * Restarting with stat
2025-05-08 15:13:23,860 WARNING: * Debugger is active!
2025-05-08 15:13:23,860 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:14:42,031 INFO:127.0.0.1 - - [08/May/2025 15:14:42] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:14:48,321 INFO:[UserMessage] Received: create s3
2025-05-08 15:14:48,678 INFO:127.0.0.1 - - [08/May/2025 15:14:48] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:15:10,819 INFO:127.0.0.1 - - [08/May/2025 15:15:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:15:17,708 INFO:[UserMessage] Received: upload file
2025-05-08 15:15:17,708 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 15:15:19,502 INFO:127.0.0.1 - - [08/May/2025 15:15:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:15:35,414 INFO:127.0.0.1 - - [08/May/2025 15:15:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:25:17,911 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-08 15:25:18,683 INFO: * Restarting with stat
2025-05-08 15:25:27,048 WARNING: * Debugger is active!
2025-05-08 15:25:27,049 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:28:08,203 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 15:28:08,872 INFO: * Restarting with stat
2025-05-08 15:28:17,116 WARNING: * Debugger is active!
2025-05-08 15:28:17,118 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:33:21,470 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 15:33:22,148 INFO: * Restarting with stat
2025-05-08 15:33:30,233 WARNING: * Debugger is active!
2025-05-08 15:33:30,233 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:41:46,096 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 15:41:46,783 INFO: * Restarting with stat
2025-05-08 15:41:55,414 WARNING: * Debugger is active!
2025-05-08 15:41:55,417 INFO: * Debugger PIN: 379-540-163
2025-05-08 15:42:11,525 INFO:127.0.0.1 - - [08/May/2025 15:42:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:42:17,602 INFO:[UserMessage] Received: upload file
2025-05-08 15:42:17,602 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 15:42:19,475 INFO:127.0.0.1 - - [08/May/2025 15:42:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 15:42:36,859 INFO:127.0.0.1 - - [08/May/2025 15:42:36] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 18:25:22,734 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 18:25:22,734 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 18:25:22,739 INFO: * Restarting with stat
2025-05-08 18:25:39,044 WARNING: * Debugger is active!
2025-05-08 18:25:39,064 INFO: * Debugger PIN: 379-540-163
2025-05-08 18:26:18,162 INFO:127.0.0.1 - - [08/May/2025 18:26:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 18:26:44,068 INFO:127.0.0.1 - - [08/May/2025 18:26:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 18:27:46,536 ERROR:An error occurred (BucketAlreadyExists) when calling the CreateBucket operation: The requested bucket name is not available. The bucket namespace is shared by all users of the system. Please select a different name and try again.
2025-05-08 18:27:46,896 INFO:127.0.0.1 - - [08/May/2025 18:27:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 18:28:01,782 INFO:127.0.0.1 - - [08/May/2025 18:28:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 18:28:10,832 INFO:[UserMessage] Received: upload file
2025-05-08 18:28:10,832 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 18:28:12,863 INFO:127.0.0.1 - - [08/May/2025 18:28:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 18:28:32,796 INFO:127.0.0.1 - - [08/May/2025 18:28:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:05,431 INFO:127.0.0.1 - - [08/May/2025 20:47:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:07,594 INFO:127.0.0.1 - - [08/May/2025 20:47:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:08,328 INFO:127.0.0.1 - - [08/May/2025 20:47:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:08,332 INFO:127.0.0.1 - - [08/May/2025 20:47:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:08,745 INFO:127.0.0.1 - - [08/May/2025 20:47:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:34,165 INFO:127.0.0.1 - - [08/May/2025 20:47:34] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:35,918 INFO:127.0.0.1 - - [08/May/2025 20:47:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:47:49,647 INFO:127.0.0.1 - - [08/May/2025 20:47:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:48:00,834 INFO:[UserMessage] Received: help
2025-05-08 20:48:01,263 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:48:35,474 INFO:127.0.0.1 - - [08/May/2025 20:48:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:48:47,142 INFO:127.0.0.1 - - [08/May/2025 20:48:47] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:48:58,588 INFO:[UserMessage] Received: <at>tikogen</at> help
2025-05-08 20:48:58,616 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:49:26,015 INFO:127.0.0.1 - - [08/May/2025 20:49:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:49:52,273 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:49:52,323 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:49:52,662 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:49:52,681 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:49:52,710 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:49:52,889 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:49:53,073 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:49:54,344 INFO:127.0.0.1 - - [08/May/2025 20:49:54] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:50:06,653 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:50:06,653 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:50:06,840 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:50:07,000 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:50:08,651 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:51:03,116 INFO:127.0.0.1 - - [08/May/2025 20:51:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:51:03,289 INFO:127.0.0.1 - - [08/May/2025 20:51:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:51:20,079 INFO:[UserMessage] Received: upload file
2025-05-08 20:51:20,079 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 20:51:21,864 INFO:127.0.0.1 - - [08/May/2025 20:51:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:51:40,267 INFO:127.0.0.1 - - [08/May/2025 20:51:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:52:06,424 INFO:127.0.0.1 - - [08/May/2025 20:52:06] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:52:22,056 INFO:[UserMessage] Received: upload file
2025-05-08 20:52:22,056 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 20:52:23,678 INFO:127.0.0.1 - - [08/May/2025 20:52:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:52:25,709 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:52:25,740 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:52:25,863 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:52:25,996 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:52:26,337 INFO:127.0.0.1 - - [08/May/2025 20:52:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:52:44,287 INFO:127.0.0.1 - - [08/May/2025 20:52:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:52:46,912 INFO:127.0.0.1 - - [08/May/2025 20:52:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:52:55,239 INFO:127.0.0.1 - - [08/May/2025 20:52:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:53:09,825 INFO:127.0.0.1 - - [08/May/2025 20:53:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:53:47,073 INFO:127.0.0.1 - - [08/May/2025 20:53:47] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:53:47,177 INFO:127.0.0.1 - - [08/May/2025 20:53:47] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:04,100 INFO:127.0.0.1 - - [08/May/2025 20:54:04] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:04,160 INFO:127.0.0.1 - - [08/May/2025 20:54:04] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:05,991 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:54:06,007 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:54:06,101 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:54:06,199 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:54:07,034 INFO:127.0.0.1 - - [08/May/2025 20:54:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:25,761 INFO:127.0.0.1 - - [08/May/2025 20:54:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:31,659 INFO:127.0.0.1 - - [08/May/2025 20:54:31] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:38,904 INFO:[UserMessage] Received: create s3
2025-05-08 20:54:39,234 INFO:127.0.0.1 - - [08/May/2025 20:54:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:54:46,733 INFO:[UserMessage] Received: create iam
2025-05-08 20:54:46,763 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:55:15,620 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:55:15,658 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:55:15,856 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:55:15,940 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:55:17,689 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:55:45,247 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:55:45,257 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:55:45,368 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:55:45,472 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:55:45,586 INFO:127.0.0.1 - - [08/May/2025 20:55:45] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 20:57:23,694 INFO:[UserMessage] Received: create rds
2025-05-08 20:57:23,710 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:57:49,225 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 20:57:49,251 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 20:57:49,263 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 20:57:49,329 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 20:57:49,414 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:00:51,007 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:00:51,042 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:00:51,056 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:00:51,188 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:00:51,355 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:04:26,830 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:04:26,852 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:04:26,858 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:04:26,959 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:04:27,093 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:07:19,880 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:07:19,911 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:07:20,042 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:07:20,134 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:07:23,681 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:07:26,096 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:07:29,067 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:07:31,316 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:07:33,595 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:07:35,956 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:07:36,457 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:10:37,925 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:10:37,957 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:10:38,061 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:10:38,159 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:10:39,842 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:10:42,223 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:10:44,215 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:10:46,492 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:10:49,599 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:10:52,812 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:10:53,238 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:13:55,043 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:13:55,070 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:13:55,193 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:13:55,309 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:13:56,961 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:13:59,276 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:14:01,284 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:14:03,494 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:14:05,558 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:14:07,925 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:14:08,360 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:17:18,169 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:17:18,200 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:17:18,328 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:17:18,452 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:17:20,089 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:17:22,444 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:17:25,007 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:17:27,397 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:17:29,677 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:17:31,993 WARNING:Private subnet detected: subnet-12345678. Consider using NAT Gateway or SSM Session Manager.
2025-05-08 21:17:32,490 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:19:40,875 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 21:19:40,924 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 21:19:40,932 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 21:19:41,068 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:19:41,217 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 21:29:41,339 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out after 600.0 seconds.
2025-05-08 21:29:41,658 INFO:127.0.0.1 - - [08/May/2025 21:29:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:20:21,127 INFO:127.0.0.1 - - [08/May/2025 22:20:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:21:07,494 INFO:127.0.0.1 - - [08/May/2025 22:21:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:21:09,702 INFO:[UserMessage] Received: create s3
2025-05-08 22:21:10,021 INFO:127.0.0.1 - - [08/May/2025 22:21:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:21:13,953 INFO:[UserMessage] Received: upload bucket
2025-05-08 22:21:14,030 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 22:21:23,439 INFO:[UserMessage] Received: upload to s3
2025-05-08 22:21:23,439 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 22:21:25,248 INFO:127.0.0.1 - - [08/May/2025 22:21:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:21:37,012 ERROR:Exception while exporting Span batch.
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1395, in getresponse
    response.begin()
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\urllib3\connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1395, in getresponse
    response.begin()
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 294, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\opentelemetry\sdk\trace\export\__init__.py", line 362, in _export_batch
    self.span_exporter.export(self.spans_list[:idx])  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\opentelemetry\exporter\otlp\proto\http\trace_exporter\__init__.py", line 189, in export
    return self._export_serialized_spans(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\opentelemetry\exporter\otlp\proto\http\trace_exporter\__init__.py", line 159, in _export_serialized_spans
    resp = self._export(serialized_data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\opentelemetry\exporter\otlp\proto\http\trace_exporter\__init__.py", line 133, in _export
    return self._session.post(
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\requests\sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\requests\adapters.py", line 682, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-05-08 22:21:53,368 INFO:127.0.0.1 - - [08/May/2025 22:21:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:22:25,461 INFO:127.0.0.1 - - [08/May/2025 22:22:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:31:14,564 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out after 600.0 seconds.
2025-05-08 22:31:14,576 ERROR:Error processing activity: cannot schedule new futures after interpreter shutdown
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 174, in run_pipeline
    return await self._middleware.receive_activity_with_status(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 69, in receive_activity_with_status
    return await self.receive_activity_internal(context, callback)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 79, in receive_activity_internal
    return await callback(context)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\activity_handler.py", line 70, in on_turn
    await self.on_message_activity(turn_context)
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 253, in on_message_activity
    await turn_context.send_activity(response)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 68, in messages
    response = await adapter.process_activity(activity, auth_header, bot.on_turn)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 445, in process_activity
    return await self.process_activity_with_identity(activity, identity, logic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 487, in process_activity_with_identity
    await self.run_pipeline(context, logic)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 179, in run_pipeline
    await self.on_turn_error(context, error)
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 49, in on_error
    await context.send_activity("Sorry, something went wrong processing your request.")
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
2025-05-08 22:31:14,894 INFO:127.0.0.1 - - [08/May/2025 22:31:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 500 -
2025-05-08 22:35:13,175 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 22:35:13,175 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 22:35:13,177 INFO: * Restarting with stat
2025-05-08 22:35:21,281 WARNING: * Debugger is active!
2025-05-08 22:35:21,281 INFO: * Debugger PIN: 379-540-163
2025-05-08 22:35:35,478 INFO:[UserMessage] Received: upload file
2025-05-08 22:35:35,478 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 22:35:39,180 INFO:127.0.0.1 - - [08/May/2025 22:35:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:35:49,918 INFO:127.0.0.1 - - [08/May/2025 22:35:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:36:09,637 INFO:127.0.0.1 - - [08/May/2025 22:36:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 22:38:19,680 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 22:38:20,597 INFO: * Restarting with stat
2025-05-08 22:38:31,427 WARNING: * Debugger is active!
2025-05-08 22:38:31,430 INFO: * Debugger PIN: 379-540-163
2025-05-08 22:44:54,346 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 22:44:55,072 INFO: * Restarting with stat
2025-05-08 22:45:03,549 WARNING: * Debugger is active!
2025-05-08 22:45:03,549 INFO: * Debugger PIN: 379-540-163
2025-05-08 22:47:59,798 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-08 22:48:00,565 INFO: * Restarting with stat
2025-05-08 22:48:08,895 WARNING: * Debugger is active!
2025-05-08 22:48:08,896 INFO: * Debugger PIN: 379-540-163
2025-05-08 23:18:37,878 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 23:18:37,879 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 23:18:37,881 INFO: * Restarting with stat
2025-05-08 23:18:46,536 WARNING: * Debugger is active!
2025-05-08 23:18:46,539 INFO: * Debugger PIN: 379-540-163
2025-05-08 23:19:10,350 INFO:127.0.0.1 - - [08/May/2025 23:19:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:19:13,486 INFO:[UserMessage] Received: upload files
2025-05-08 23:19:13,487 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 23:19:15,478 INFO:127.0.0.1 - - [08/May/2025 23:19:15] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:19:28,803 INFO:127.0.0.1 - - [08/May/2025 23:19:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:36:40,636 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 23:36:40,636 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 23:36:40,638 INFO: * Restarting with stat
2025-05-08 23:36:49,334 WARNING: * Debugger is active!
2025-05-08 23:36:49,334 INFO: * Debugger PIN: 379-540-163
2025-05-08 23:37:13,272 INFO:127.0.0.1 - - [08/May/2025 23:37:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:37:25,383 INFO:[UserMessage] Received: upload file in s2
2025-05-08 23:37:25,383 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 23:37:27,343 INFO:127.0.0.1 - - [08/May/2025 23:37:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:37:41,918 INFO:127.0.0.1 - - [08/May/2025 23:37:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:37:51,219 INFO:127.0.0.1 - - [08/May/2025 23:37:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:42:19,592 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-08 23:42:19,592 INFO:[33mPress CTRL+C to quit[0m
2025-05-08 23:42:19,592 INFO: * Restarting with stat
2025-05-08 23:42:27,845 WARNING: * Debugger is active!
2025-05-08 23:42:27,845 INFO: * Debugger PIN: 379-540-163
2025-05-08 23:42:39,465 INFO:[UserMessage] Received: upload folder
2025-05-08 23:42:39,516 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 23:42:45,379 INFO:[UserMessage] Received: upload file
2025-05-08 23:42:45,379 INFO:[IntentMatch] Upload file intent matched.
2025-05-08 23:42:48,443 INFO:127.0.0.1 - - [08/May/2025 23:42:48] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:42:54,328 INFO:127.0.0.1 - - [08/May/2025 23:42:54] "[35m[1mPOST /api/messages HTTP/1.1[0m" 501 -
2025-05-08 23:43:14,029 INFO:127.0.0.1 - - [08/May/2025 23:43:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 501 -
2025-05-08 23:44:34,142 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 23:44:34,151 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 23:44:34,639 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:44:34,639 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:44:34,688 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 23:44:34,716 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:44:34,775 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:47:21,104 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 23:47:21,115 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 23:47:21,126 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 23:47:21,233 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:47:21,313 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:49:25,372 INFO:127.0.0.1 - - [08/May/2025 23:49:25] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:49:27,639 INFO:127.0.0.1 - - [08/May/2025 23:49:27] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:49:55,711 INFO:127.0.0.1 - - [08/May/2025 23:49:55] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:49:56,363 INFO:127.0.0.1 - - [08/May/2025 23:49:56] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:50:28,915 INFO:127.0.0.1 - - [08/May/2025 23:50:28] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:50:31,620 INFO:127.0.0.1 - - [08/May/2025 23:50:31] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:51:09,420 INFO:127.0.0.1 - - [08/May/2025 23:51:09] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:51:19,042 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 23:51:19,055 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 23:51:19,070 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 23:51:19,164 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:51:19,247 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:55:17,881 INFO:127.0.0.1 - - [08/May/2025 23:55:17] "OPTIONS /api/messages HTTP/1.1" 200 -
2025-05-08 23:55:26,486 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-08 23:55:26,545 INFO:Wrapper: Completed Call, calling success_handler
2025-05-08 23:55:26,556 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 23:55:28,405 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:55:28,456 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-08 23:58:06,285 INFO:127.0.0.1 - - [08/May/2025 23:58:06] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:58:08,904 INFO:127.0.0.1 - - [08/May/2025 23:58:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:58:11,819 INFO:127.0.0.1 - - [08/May/2025 23:58:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:58:18,426 INFO:127.0.0.1 - - [08/May/2025 23:58:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:58:18,428 INFO:127.0.0.1 - - [08/May/2025 23:58:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:58:34,131 INFO:127.0.0.1 - - [08/May/2025 23:58:34] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:58:58,640 INFO:127.0.0.1 - - [08/May/2025 23:58:58] "[35m[1mPOST /api/messages HTTP/1.1[0m" 501 -
2025-05-08 23:59:05,159 INFO:127.0.0.1 - - [08/May/2025 23:59:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:59:07,169 INFO:127.0.0.1 - - [08/May/2025 23:59:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:59:19,408 INFO:127.0.0.1 - - [08/May/2025 23:59:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-08 23:59:32,414 INFO:[UserMessage] Received: help
2025-05-08 23:59:32,654 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-08 23:59:47,766 INFO:127.0.0.1 - - [08/May/2025 23:59:47] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:00:12,426 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 00:00:12,505 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 00:00:12,538 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 00:00:12,604 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 00:00:12,673 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 00:01:03,409 INFO:127.0.0.1 - - [09/May/2025 00:01:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:01:20,335 INFO:[UserMessage] Received: upload file
2025-05-09 00:01:20,335 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 00:01:22,582 INFO:127.0.0.1 - - [09/May/2025 00:01:22] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:01:28,553 INFO:127.0.0.1 - - [09/May/2025 00:01:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:01:50,845 INFO:127.0.0.1 - - [09/May/2025 00:01:50] "[35m[1mPOST /api/messages HTTP/1.1[0m" 501 -
2025-05-09 00:02:25,403 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 00:02:25,466 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 00:02:25,483 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 00:02:25,572 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 00:02:25,668 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 00:05:36,055 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 00:05:36,055 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 00:05:36,062 INFO: * Restarting with stat
2025-05-09 00:05:53,771 WARNING: * Debugger is active!
2025-05-09 00:05:53,778 INFO: * Debugger PIN: 379-540-163
2025-05-09 00:05:56,711 INFO:127.0.0.1 - - [09/May/2025 00:05:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:06:01,031 INFO:[UserMessage] Received: upload file
2025-05-09 00:06:01,031 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 00:06:03,631 INFO:127.0.0.1 - - [09/May/2025 00:06:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:06:17,832 INFO:127.0.0.1 - - [09/May/2025 00:06:17] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:07:05,509 INFO:127.0.0.1 - - [09/May/2025 00:07:05] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:07:18,082 INFO:127.0.0.1 - - [09/May/2025 00:07:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:07:39,181 INFO:[UserMessage] Received: upload file
2025-05-09 00:07:39,181 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 00:07:41,330 INFO:127.0.0.1 - - [09/May/2025 00:07:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:07:51,844 INFO:127.0.0.1 - - [09/May/2025 00:07:51] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:14:59,871 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 00:14:59,871 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 00:14:59,876 INFO: * Restarting with stat
2025-05-09 00:15:16,305 WARNING: * Debugger is active!
2025-05-09 00:15:16,314 INFO: * Debugger PIN: 379-540-163
2025-05-09 00:15:32,989 INFO:127.0.0.1 - - [09/May/2025 00:15:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:15:47,268 INFO:[UserMessage] Received: upload file
2025-05-09 00:15:47,268 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 00:15:49,823 INFO:127.0.0.1 - - [09/May/2025 00:15:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:16:15,901 INFO:127.0.0.1 - - [09/May/2025 00:16:15] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:16:22,623 INFO:127.0.0.1 - - [09/May/2025 00:16:22] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:16:33,375 INFO:127.0.0.1 - - [09/May/2025 00:16:33] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:22:11,528 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 00:22:11,528 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 00:22:11,532 INFO: * Restarting with stat
2025-05-09 00:22:29,590 WARNING: * Debugger is active!
2025-05-09 00:22:29,595 INFO: * Debugger PIN: 379-540-163
2025-05-09 00:22:32,986 INFO:127.0.0.1 - - [09/May/2025 00:22:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:22:35,775 INFO:[UserMessage] Received: upload file
2025-05-09 00:22:35,775 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 00:22:38,296 INFO:127.0.0.1 - - [09/May/2025 00:22:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 00:22:52,369 INFO:127.0.0.1 - - [09/May/2025 00:22:52] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 00:43:07,529 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 00:43:07,529 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 00:43:07,534 INFO: * Restarting with stat
2025-05-09 00:43:24,773 WARNING: * Debugger is active!
2025-05-09 00:43:24,777 INFO: * Debugger PIN: 379-540-163
2025-05-09 00:43:27,249 INFO:127.0.0.1 - - [09/May/2025 00:43:27] "GET /upload HTTP/1.1" 200 -
2025-05-09 00:43:27,942 INFO:127.0.0.1 - - [09/May/2025 00:43:27] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-09 00:45:07,245 INFO:127.0.0.1 - - [09/May/2025 00:45:07] "[35m[1mPOST /upload HTTP/1.1[0m" 500 -
2025-05-09 00:45:07,573 INFO:127.0.0.1 - - [09/May/2025 00:45:07] "GET /upload?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1" 200 -
2025-05-09 00:45:07,593 INFO:127.0.0.1 - - [09/May/2025 00:45:07] "GET /upload?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1" 200 -
2025-05-09 00:45:07,809 INFO:127.0.0.1 - - [09/May/2025 00:45:07] "GET /upload?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2025-05-09 00:46:24,925 INFO:127.0.0.1 - - [09/May/2025 00:46:24] "[33mGET /uploadhttps://4c4c-103-208-230-127.ngrok-free.app/upload HTTP/1.1[0m" 404 -
2025-05-09 00:59:41,513 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 00:59:41,513 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 00:59:41,517 INFO: * Restarting with stat
2025-05-09 00:59:58,973 WARNING: * Debugger is active!
2025-05-09 00:59:58,978 INFO: * Debugger PIN: 379-540-163
2025-05-09 00:59:59,426 INFO:127.0.0.1 - - [09/May/2025 00:59:59] "GET /upload HTTP/1.1" 200 -
2025-05-09 01:00:08,820 INFO:127.0.0.1 - - [09/May/2025 01:00:08] "[33mPOST /api/messages HTTP/1.1[0m" 404 -
2025-05-09 01:00:40,357 INFO:127.0.0.1 - - [09/May/2025 01:00:40] "[33mPOST /api/messages HTTP/1.1[0m" 404 -
2025-05-09 01:01:23,332 INFO:127.0.0.1 - - [09/May/2025 01:01:23] "[33mPOST /api/messages HTTP/1.1[0m" 404 -
2025-05-09 01:09:38,596 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 01:09:38,596 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 01:09:38,600 INFO: * Restarting with stat
2025-05-09 01:09:56,185 WARNING: * Debugger is active!
2025-05-09 01:09:56,192 INFO: * Debugger PIN: 379-540-163
2025-05-09 01:09:59,332 INFO:127.0.0.1 - - [09/May/2025 01:09:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 01:10:01,532 INFO:127.0.0.1 - - [09/May/2025 01:10:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 01:10:07,858 INFO:[UserMessage] Received: upload file
2025-05-09 01:10:07,860 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 01:10:10,586 INFO:127.0.0.1 - - [09/May/2025 01:10:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 01:10:24,413 INFO:127.0.0.1 - - [09/May/2025 01:10:24] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 01:15:59,669 INFO:127.0.0.1 - - [09/May/2025 01:15:59] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 16:23:27,918 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 16:23:27,918 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 16:23:27,918 INFO: * Restarting with stat
2025-05-09 16:23:36,390 WARNING: * Debugger is active!
2025-05-09 16:23:36,398 INFO: * Debugger PIN: 379-540-163
2025-05-09 16:24:00,254 INFO:127.0.0.1 - - [09/May/2025 16:24:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 16:24:09,573 INFO:127.0.0.1 - - [09/May/2025 16:24:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 16:24:49,423 INFO:127.0.0.1 - - [09/May/2025 16:24:49] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 16:25:37,291 INFO:[UserMessage] Received: list bucket
2025-05-09 16:25:37,505 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 16:26:32,051 INFO:[UserMessage] Received: download file
2025-05-09 16:26:32,065 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 16:27:14,434 INFO:[UserMessage] Received: download file s3
2025-05-09 16:27:16,608 INFO:127.0.0.1 - - [09/May/2025 16:27:16] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 16:27:27,763 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 16:27:27,780 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 16:27:27,879 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 16:27:27,880 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 16:27:27,973 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 16:27:28,035 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 16:27:29,207 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 16:27:29,690 INFO:127.0.0.1 - - [09/May/2025 16:27:29] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 16:27:45,942 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 16:27:45,947 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 16:27:45,971 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 16:27:46,032 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 16:27:46,142 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 16:28:38,529 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 16:28:38,533 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 16:28:38,602 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 16:28:38,606 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 16:29:40,560 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 16:29:40,562 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 16:29:40,563 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 16:29:40,566 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 16:29:54,992 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 16:29:54,992 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 16:29:55,086 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 16:29:55,090 ERROR:Error processing activity: cannot schedule new futures after interpreter shutdown
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 174, in run_pipeline
    return await self._middleware.receive_activity_with_status(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 69, in receive_activity_with_status
    return await self.receive_activity_internal(context, callback)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 79, in receive_activity_internal
    return await callback(context)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\activity_handler.py", line 70, in on_turn
    await self.on_message_activity(turn_context)
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 260, in on_message_activity
    await turn_context.send_activity(response)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 69, in messages
    response = await adapter.process_activity(activity, auth_header, bot.on_turn)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 445, in process_activity
    return await self.process_activity_with_identity(activity, identity, logic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 487, in process_activity_with_identity
    await self.run_pipeline(context, logic)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 179, in run_pipeline
    await self.on_turn_error(context, error)
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 50, in on_error
    await context.send_activity("Sorry, something went wrong processing your request.")
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
2025-05-09 16:29:55,304 INFO:127.0.0.1 - - [09/May/2025 16:29:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 500 -
2025-05-09 16:30:13,328 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 16:30:13,330 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 16:30:13,332 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 16:30:13,336 ERROR:Error processing activity: cannot schedule new futures after interpreter shutdown
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 174, in run_pipeline
    return await self._middleware.receive_activity_with_status(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 69, in receive_activity_with_status
    return await self.receive_activity_internal(context, callback)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 79, in receive_activity_internal
    return await callback(context)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\activity_handler.py", line 70, in on_turn
    await self.on_message_activity(turn_context)
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 260, in on_message_activity
    await turn_context.send_activity(response)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 69, in messages
    response = await adapter.process_activity(activity, auth_header, bot.on_turn)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 445, in process_activity
    return await self.process_activity_with_identity(activity, identity, logic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 487, in process_activity_with_identity
    await self.run_pipeline(context, logic)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 179, in run_pipeline
    await self.on_turn_error(context, error)
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 50, in on_error
    await context.send_activity("Sorry, something went wrong processing your request.")
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
2025-05-09 16:30:13,342 INFO:127.0.0.1 - - [09/May/2025 16:30:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 500 -
2025-05-09 17:18:27,783 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 17:18:27,784 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 17:18:27,786 INFO: * Restarting with stat
2025-05-09 17:18:36,298 WARNING: * Debugger is active!
2025-05-09 17:18:36,302 INFO: * Debugger PIN: 379-540-163
2025-05-09 17:19:48,903 INFO:127.0.0.1 - - [09/May/2025 17:19:48] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:19:53,269 INFO:[UserMessage] Received: dowload file
2025-05-09 17:19:53,323 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:20:07,587 INFO:[UserMessage] Received: download file s3
2025-05-09 17:20:09,581 INFO:127.0.0.1 - - [09/May/2025 17:20:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:20:19,599 INFO:127.0.0.1 - - [09/May/2025 17:20:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:20:27,265 INFO:127.0.0.1 - - [09/May/2025 17:20:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:21:32,239 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:21:32,250 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:21:32,738 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:21:32,740 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:21:32,779 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:21:32,814 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:21:32,871 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:21:48,621 INFO:[UserMessage] Received: download file s3
2025-05-09 17:21:50,246 INFO:127.0.0.1 - - [09/May/2025 17:21:50] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:21:55,863 INFO:127.0.0.1 - - [09/May/2025 17:21:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:22:05,107 INFO:127.0.0.1 - - [09/May/2025 17:22:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:22:17,689 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:22:17,706 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:22:17,728 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:22:17,783 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:22:17,841 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:23:44,189 INFO:127.0.0.1 - - [09/May/2025 17:23:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:23:51,261 INFO:127.0.0.1 - - [09/May/2025 17:23:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:23:58,883 INFO:[UserMessage] Received: create s3
2025-05-09 17:24:00,541 INFO:127.0.0.1 - - [09/May/2025 17:24:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:24:12,606 INFO:127.0.0.1 - - [09/May/2025 17:24:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:24:27,031 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:24:27,031 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:24:27,066 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:24:27,105 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:24:27,171 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:24:39,370 INFO:[UserMessage] Received: terminate ec2
2025-05-09 17:24:39,390 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:24:55,460 INFO:[UserMessage] Received: terminate vpc
2025-05-09 17:24:55,476 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:25:11,436 INFO:[UserMessage] Received: delete vpc
2025-05-09 17:25:11,454 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:26:01,767 INFO:[UserMessage] Received: delet ec2
2025-05-09 17:26:01,787 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:28:03,114 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:28:03,119 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:28:03,168 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:28:03,209 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:28:03,326 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:30:13,098 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:30:13,102 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:30:13,197 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:30:13,272 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:30:14,672 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:30:44,322 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:30:44,322 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:30:44,401 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:30:44,480 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:30:45,700 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:30:59,744 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:30:59,745 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:30:59,828 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:30:59,901 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:31:01,286 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:31:21,007 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:31:21,012 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:31:21,091 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:31:21,160 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:31:22,472 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:34:12,717 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:34:12,724 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:34:12,765 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:34:12,862 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:34:12,958 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:36:03,384 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:36:03,399 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:36:03,500 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:36:03,609 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:36:03,756 INFO:127.0.0.1 - - [09/May/2025 17:36:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:36:21,100 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:36:21,115 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:36:21,115 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:36:21,227 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:36:21,372 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:36:39,308 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:36:39,315 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:36:39,322 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:36:39,420 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:36:39,540 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:37:12,662 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:37:12,670 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:37:12,790 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:37:12,897 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:37:13,063 INFO:127.0.0.1 - - [09/May/2025 17:37:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 17:39:20,599 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:39:20,614 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:39:20,996 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:39:20,996 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:39:21,091 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:41:19,011 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:41:19,033 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:41:19,035 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:41:19,145 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:41:19,241 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:42:40,707 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:42:40,707 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:42:40,724 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:42:40,839 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:42:40,948 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:44:49,906 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:44:49,906 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:44:49,952 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:44:50,034 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:44:50,162 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:46:52,516 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:46:52,516 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:46:52,629 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:46:52,741 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:46:54,179 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:49:06,020 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:49:06,030 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:49:06,037 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:49:06,140 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:49:06,259 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:51:10,336 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:51:10,340 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:51:10,440 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:51:10,594 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:51:11,683 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:54:06,858 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:54:06,868 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:54:06,975 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:54:07,079 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:54:36,893 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:56:06,141 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:56:06,141 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:56:06,161 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 17:56:06,260 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:56:06,364 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:58:27,670 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 17:58:27,679 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 17:58:27,775 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:58:27,893 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 17:58:28,019 INFO:127.0.0.1 - - [09/May/2025 17:58:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 18:00:26,625 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:00:26,641 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:00:26,648 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:00:26,753 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:00:26,863 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:02:29,603 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:02:29,607 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:02:29,607 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:02:29,728 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:02:29,845 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:05:36,157 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:05:36,157 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:05:36,444 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:05:36,573 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:06:07,827 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:07:33,099 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:07:33,114 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:07:33,114 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:07:33,226 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:07:33,321 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:10:00,977 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:10:00,990 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:10:00,995 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:10:01,150 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:10:01,299 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:11:52,945 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:11:52,961 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:11:52,961 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:11:53,073 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:11:53,187 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:14:59,827 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:14:59,844 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:14:59,955 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:15:00,068 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:15:29,251 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:17:09,491 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:17:09,509 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:17:09,514 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:17:09,610 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:17:09,712 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:19:14,976 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:19:15,001 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:19:15,006 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:19:15,104 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:19:15,216 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:21:48,706 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:21:48,729 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:21:48,840 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:21:48,957 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:21:50,094 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:25:14,492 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:25:14,527 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:25:14,641 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:25:14,748 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:25:19,667 WARNING:Private subnet detected: subnet-01234567. Consider using NAT Gateway or SSM Session Manager.
2025-05-09 18:25:24,714 WARNING:Private subnet detected: subnet-01234567. Consider using NAT Gateway or SSM Session Manager.
2025-05-09 18:25:29,846 WARNING:Private subnet detected: subnet-01234567. Consider using NAT Gateway or SSM Session Manager.
2025-05-09 18:25:34,690 WARNING:Private subnet detected: subnet-01234567. Consider using NAT Gateway or SSM Session Manager.
2025-05-09 18:25:39,564 WARNING:Private subnet detected: subnet-01234567. Consider using NAT Gateway or SSM Session Manager.
2025-05-09 18:25:44,751 WARNING:Private subnet detected: subnet-01234567. Consider using NAT Gateway or SSM Session Manager.
2025-05-09 18:25:46,413 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:27:20,293 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:27:20,309 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:27:20,319 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:27:20,435 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:27:20,540 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:29:48,490 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:29:48,514 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:29:48,567 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:29:48,683 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:29:48,803 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:32:01,158 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:32:01,174 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:32:01,271 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:32:01,399 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:32:02,803 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:34:14,840 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:34:14,866 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:34:14,868 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:34:14,976 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:34:15,090 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:36:20,155 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:36:20,193 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:36:20,200 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:36:20,318 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:36:20,456 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:38:51,052 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:38:51,083 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:38:51,090 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:38:51,212 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:38:51,372 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:40:50,687 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:40:50,705 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:40:50,707 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:40:50,799 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:40:50,913 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:43:22,940 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:43:22,961 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:43:22,970 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:43:23,074 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:43:23,185 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:46:03,217 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:46:03,240 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:46:03,258 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:46:03,366 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:46:03,473 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:48:41,688 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:48:41,719 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:48:41,721 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:48:41,853 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:48:41,947 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:51:24,460 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:51:24,490 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:51:24,590 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:51:24,704 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:51:56,345 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:54:00,756 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:54:00,774 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:54:00,787 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:54:00,891 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:54:00,995 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:56:52,579 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:56:52,597 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:56:52,714 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:56:52,808 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:57:22,974 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:59:38,900 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 18:59:38,935 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 18:59:38,946 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 18:59:39,043 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 18:59:39,140 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:02:30,066 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:02:30,099 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:02:30,215 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:02:30,339 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:03:03,073 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:05:17,916 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:05:17,936 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:05:17,948 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:05:18,039 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:05:18,140 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:08:11,249 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:08:11,297 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:08:11,517 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:08:11,599 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:08:41,839 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:11:06,958 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:11:06,990 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:11:07,007 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:11:07,117 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:11:07,246 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:13:59,304 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:13:59,340 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:13:59,440 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:13:59,542 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:14:30,089 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:16:52,164 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:16:52,190 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:16:52,198 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:16:52,315 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:16:52,440 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:20:06,071 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:20:06,104 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:20:06,210 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:20:06,311 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 19:20:36,275 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:23:03,960 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 19:23:04,009 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 19:23:04,051 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 19:23:04,090 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 19:56:08,342 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 19:56:08,343 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 19:56:08,346 INFO: * Restarting with stat
2025-05-09 19:56:16,614 WARNING: * Debugger is active!
2025-05-09 19:56:16,628 INFO: * Debugger PIN: 379-540-163
2025-05-09 19:56:23,963 INFO:127.0.0.1 - - [09/May/2025 19:56:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 19:56:30,329 INFO:[UserMessage] Received: upload file
2025-05-09 19:56:30,329 INFO:[IntentMatch] Upload file intent matched.
2025-05-09 19:56:32,304 INFO:127.0.0.1 - - [09/May/2025 19:56:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 19:56:36,434 INFO:127.0.0.1 - - [09/May/2025 19:56:36] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 19:56:44,874 INFO:127.0.0.1 - - [09/May/2025 19:56:44] "GET /upload HTTP/1.1" 200 -
2025-05-09 19:56:59,769 INFO:127.0.0.1 - - [09/May/2025 19:56:59] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 19:56:59,960 INFO:127.0.0.1 - - [09/May/2025 19:56:59] "GET /upload HTTP/1.1" 200 -
2025-05-09 19:57:25,231 INFO:127.0.0.1 - - [09/May/2025 19:57:25] "POST /upload HTTP/1.1" 200 -
2025-05-09 19:57:26,494 INFO:127.0.0.1 - - [09/May/2025 19:57:26] "POST /upload HTTP/1.1" 200 -
2025-05-09 19:57:26,651 INFO:127.0.0.1 - - [09/May/2025 19:57:26] "POST /upload HTTP/1.1" 200 -
2025-05-09 19:58:31,913 INFO:127.0.0.1 - - [09/May/2025 19:58:31] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 19:58:32,166 INFO:127.0.0.1 - - [09/May/2025 19:58:32] "GET /upload HTTP/1.1" 200 -
2025-05-09 20:00:33,444 INFO:127.0.0.1 - - [09/May/2025 20:00:33] "POST /api/messages HTTP/1.1" 200 -
2025-05-09 20:00:33,630 INFO:127.0.0.1 - - [09/May/2025 20:00:33] "GET /upload HTTP/1.1" 200 -
2025-05-09 20:01:32,621 INFO:127.0.0.1 - - [09/May/2025 20:01:32] "GET /upload HTTP/1.1" 200 -
2025-05-09 20:01:32,965 INFO:127.0.0.1 - - [09/May/2025 20:01:32] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-05-09 20:02:06,262 INFO:[UserMessage] Received: download form
2025-05-09 20:02:06,311 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 20:02:15,021 INFO:[UserMessage] Received: download file
2025-05-09 20:02:17,121 INFO:127.0.0.1 - - [09/May/2025 20:02:17] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 20:02:25,067 INFO:127.0.0.1 - - [09/May/2025 20:02:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 20:02:38,279 INFO:127.0.0.1 - - [09/May/2025 20:02:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 20:04:44,689 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 20:04:44,708 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 20:04:45,228 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 20:04:45,228 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 20:04:45,274 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 20:04:45,322 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 20:04:45,370 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 20:06:33,550 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 20:06:33,567 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 20:06:33,583 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 20:06:33,586 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 20:08:21,042 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 20:08:21,042 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 20:08:21,058 ERROR:LiteLLM call failed: cannot schedule new futures after shutdown
2025-05-09 20:08:21,063 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 23:05:07,433 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 23:05:07,433 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 23:05:07,433 INFO: * Restarting with stat
2025-05-09 23:05:15,403 WARNING: * Debugger is active!
2025-05-09 23:05:15,407 INFO: * Debugger PIN: 379-540-163
2025-05-09 23:05:23,615 INFO:127.0.0.1 - - [09/May/2025 23:05:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:05:32,550 INFO:[UserMessage] Received: create iam user
2025-05-09 23:05:32,882 INFO:127.0.0.1 - - [09/May/2025 23:05:32] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:06:55,744 INFO:127.0.0.1 - - [09/May/2025 23:06:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:07:20,238 INFO:127.0.0.1 - - [09/May/2025 23:07:20] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:07:36,367 INFO:127.0.0.1 - - [09/May/2025 23:07:36] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:07:40,790 INFO:127.0.0.1 - - [09/May/2025 23:07:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:08:37,133 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-09 23:08:37,849 INFO: * Restarting with stat
2025-05-09 23:08:55,235 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 23:08:55,235 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 23:08:55,239 INFO: * Restarting with stat
2025-05-09 23:09:03,337 WARNING: * Debugger is active!
2025-05-09 23:09:03,338 INFO: * Debugger PIN: 379-540-163
2025-05-09 23:09:09,129 INFO:[UserMessage] Received: create iam user
2025-05-09 23:09:10,995 INFO:127.0.0.1 - - [09/May/2025 23:09:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:09:52,207 INFO:127.0.0.1 - - [09/May/2025 23:09:52] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:16:32,327 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-09 23:16:33,192 INFO: * Restarting with stat
2025-05-09 23:19:40,474 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-09 23:19:40,474 INFO:[33mPress CTRL+C to quit[0m
2025-05-09 23:19:40,474 INFO: * Restarting with stat
2025-05-09 23:19:48,695 WARNING: * Debugger is active!
2025-05-09 23:19:48,696 INFO: * Debugger PIN: 379-540-163
2025-05-09 23:20:00,861 INFO:[UserMessage] Received: create iam user
2025-05-09 23:20:02,792 INFO:127.0.0.1 - - [09/May/2025 23:20:02] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:20:16,878 INFO:127.0.0.1 - - [09/May/2025 23:20:16] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:33:23,864 INFO:127.0.0.1 - - [09/May/2025 23:33:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:37:43,313 INFO:[UserMessage] Received: create a same user as ritom21
2025-05-09 23:37:43,408 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 23:38:51,909 INFO:[UserMessage] Received: enable mfa
2025-05-09 23:38:53,856 INFO:127.0.0.1 - - [09/May/2025 23:38:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:39:01,768 INFO:127.0.0.1 - - [09/May/2025 23:39:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:39:56,293 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 23:39:56,319 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 23:39:56,784 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:39:56,785 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:39:56,892 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:39:56,940 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:39:57,145 ERROR:An error occurred (EntityAlreadyExists) when calling the CreateUser operation: User with name ritom21 already exists.
2025-05-09 23:39:57,149 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 23:39:58,190 INFO:127.0.0.1 - - [09/May/2025 23:39:58] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:40:23,424 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 23:40:23,428 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 23:40:23,534 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:40:23,593 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:40:23,779 INFO:127.0.0.1 - - [09/May/2025 23:40:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:40:56,410 INFO:[UserMessage] Received: then create user with name sam
2025-05-09 23:40:56,732 INFO:127.0.0.1 - - [09/May/2025 23:40:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:41:09,858 INFO:[UserMessage] Received: create a same user as ritom21 with new name samriddha
2025-05-09 23:41:09,879 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 23:41:29,370 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 23:41:29,374 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 23:41:29,400 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 23:41:29,472 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:41:29,568 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:43:51,408 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 23:43:51,425 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 23:43:51,497 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:43:51,578 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:43:53,767 ERROR:An error occurred (InvalidInput) when calling the AttachUserPolicy operation: ARN arn:aws:iam::aws:policy/arn:aws:iam::AWSDefaultPolicy is not valid.
2025-05-09 23:43:53,777 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-09 23:47:59,794 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-09 23:47:59,814 INFO:Wrapper: Completed Call, calling success_handler
2025-05-09 23:48:00,163 INFO:127.0.0.1 - - [09/May/2025 23:48:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-09 23:48:00,276 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-09 23:48:00,340 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 00:47:59,581 INFO:[UserMessage] Received: create iam group
2025-05-10 00:47:59,944 INFO:127.0.0.1 - - [10/May/2025 00:47:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:48:11,594 INFO:127.0.0.1 - - [10/May/2025 00:48:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:48:21,049 INFO:127.0.0.1 - - [10/May/2025 00:48:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:48:28,600 INFO:127.0.0.1 - - [10/May/2025 00:48:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:50:24,121 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-10 00:50:25,992 INFO: * Restarting with stat
2025-05-10 00:50:42,067 WARNING: * Debugger is active!
2025-05-10 00:50:42,067 INFO: * Debugger PIN: 379-540-163
2025-05-10 00:51:03,189 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 00:51:03,189 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 00:51:03,194 INFO: * Restarting with stat
2025-05-10 00:51:12,155 WARNING: * Debugger is active!
2025-05-10 00:51:12,157 INFO: * Debugger PIN: 379-540-163
2025-05-10 00:51:21,016 INFO:127.0.0.1 - - [10/May/2025 00:51:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:51:24,837 INFO:[UserMessage] Received: create iam group
2025-05-10 00:51:25,144 INFO:127.0.0.1 - - [10/May/2025 00:51:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:51:35,010 INFO:127.0.0.1 - - [10/May/2025 00:51:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:51:49,886 INFO:[UserMessage] Received: attach user to group
2025-05-10 00:51:50,797 INFO:127.0.0.1 - - [10/May/2025 00:51:50] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:52:00,021 INFO:127.0.0.1 - - [10/May/2025 00:52:00] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:52:13,259 INFO:[UserMessage] Received: attach policy
2025-05-10 00:52:14,125 INFO:127.0.0.1 - - [10/May/2025 00:52:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:52:29,769 INFO:127.0.0.1 - - [10/May/2025 00:52:29] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:54:56,618 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 00:54:56,618 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 00:54:56,618 INFO: * Restarting with stat
2025-05-10 00:55:05,069 WARNING: * Debugger is active!
2025-05-10 00:55:05,071 INFO: * Debugger PIN: 379-540-163
2025-05-10 00:55:10,441 INFO:127.0.0.1 - - [10/May/2025 00:55:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:55:21,614 INFO:[UserMessage] Received: attach policy
2025-05-10 00:55:23,581 INFO:127.0.0.1 - - [10/May/2025 00:55:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:56:11,340 INFO:127.0.0.1 - - [10/May/2025 00:56:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:58:36,757 INFO:127.0.0.1 - - [10/May/2025 00:58:36] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 00:58:46,533 INFO:127.0.0.1 - - [10/May/2025 00:58:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:26:13,744 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 01:26:13,744 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 01:26:13,748 INFO: * Restarting with stat
2025-05-10 01:26:22,760 WARNING: * Debugger is active!
2025-05-10 01:26:22,760 INFO: * Debugger PIN: 379-540-163
2025-05-10 01:26:30,153 INFO:[UserMessage] Received: attach policy
2025-05-10 01:26:34,055 INFO:127.0.0.1 - - [10/May/2025 01:26:34] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:26:55,320 INFO:127.0.0.1 - - [10/May/2025 01:26:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:27:17,052 INFO:127.0.0.1 - - [10/May/2025 01:27:17] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:27:30,238 INFO:127.0.0.1 - - [10/May/2025 01:27:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:28:04,669 INFO:[UserMessage] Received: inline policy
2025-05-10 01:28:06,572 INFO:127.0.0.1 - - [10/May/2025 01:28:06] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:29:35,223 INFO:127.0.0.1 - - [10/May/2025 01:29:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:29:59,217 INFO:127.0.0.1 - - [10/May/2025 01:29:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:30:37,690 INFO:127.0.0.1 - - [10/May/2025 01:30:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:31:59,113 INFO:127.0.0.1 - - [10/May/2025 01:31:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:32:37,317 INFO:[UserMessage] Received: create iam role
2025-05-10 01:32:37,706 INFO:127.0.0.1 - - [10/May/2025 01:32:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:34:58,291 INFO:127.0.0.1 - - [10/May/2025 01:34:58] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:35:43,717 INFO:127.0.0.1 - - [10/May/2025 01:35:43] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:36:43,958 INFO:[UserMessage] Received: delete iam user
2025-05-10 01:36:45,807 INFO:127.0.0.1 - - [10/May/2025 01:36:45] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:36:57,791 INFO:127.0.0.1 - - [10/May/2025 01:36:57] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:37:26,378 INFO:[UserMessage] Received: detach policy
2025-05-10 01:37:27,283 INFO:127.0.0.1 - - [10/May/2025 01:37:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:37:46,189 INFO:127.0.0.1 - - [10/May/2025 01:37:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:38:58,620 INFO:127.0.0.1 - - [10/May/2025 01:38:58] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 01:41:28,777 INFO:127.0.0.1 - - [10/May/2025 01:41:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:50:28,035 INFO:127.0.0.1 - - [10/May/2025 02:50:28] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:51:22,987 INFO:[UserMessage] Received: delete iam group
2025-05-10 02:51:23,941 INFO:127.0.0.1 - - [10/May/2025 02:51:23] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:51:59,663 INFO:127.0.0.1 - - [10/May/2025 02:51:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:52:37,698 INFO:127.0.0.1 - - [10/May/2025 02:52:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:52:56,899 INFO:127.0.0.1 - - [10/May/2025 02:52:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:53:05,066 INFO:127.0.0.1 - - [10/May/2025 02:53:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:53:53,154 INFO:[UserMessage] Received: audit iam
2025-05-10 02:53:53,498 INFO:127.0.0.1 - - [10/May/2025 02:53:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:54:01,207 INFO:127.0.0.1 - - [10/May/2025 02:54:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:54:32,980 INFO:[UserMessage] Received: create iam user
2025-05-10 02:54:33,328 INFO:127.0.0.1 - - [10/May/2025 02:54:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:54:53,731 INFO:127.0.0.1 - - [10/May/2025 02:54:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:55:10,989 INFO:[UserMessage] Received: create iam group
2025-05-10 02:55:11,363 INFO:127.0.0.1 - - [10/May/2025 02:55:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:55:25,026 INFO:127.0.0.1 - - [10/May/2025 02:55:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:55:43,528 INFO:[UserMessage] Received: attach policy
2025-05-10 02:55:44,457 INFO:127.0.0.1 - - [10/May/2025 02:55:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:56:03,137 INFO:127.0.0.1 - - [10/May/2025 02:56:03] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:56:41,032 INFO:[UserMessage] Received: detach policy
2025-05-10 02:56:42,036 INFO:127.0.0.1 - - [10/May/2025 02:56:42] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:57:07,885 INFO:127.0.0.1 - - [10/May/2025 02:57:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:57:41,513 INFO:[UserMessage] Received: mfa user
2025-05-10 02:57:44,987 INFO:127.0.0.1 - - [10/May/2025 02:57:44] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:57:51,647 INFO:127.0.0.1 - - [10/May/2025 02:57:51] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:59:27,838 INFO:127.0.0.1 - - [10/May/2025 02:59:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:59:31,865 INFO:127.0.0.1 - - [10/May/2025 02:59:31] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:59:38,584 INFO:127.0.0.1 - - [10/May/2025 02:59:38] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 02:59:53,814 INFO:[UserMessage] Received: upload file
2025-05-10 02:59:53,816 INFO:[IntentMatch] Upload file intent matched.
2025-05-10 02:59:56,264 INFO:127.0.0.1 - - [10/May/2025 02:59:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 03:00:13,632 INFO:[UserMessage] Received: delete bucket
2025-05-10 03:00:14,040 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-10 03:00:33,782 INFO:[UserMessage] Received: terminate bucket
2025-05-10 03:00:33,814 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-10 03:02:13,237 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-10 03:02:13,318 INFO:Wrapper: Completed Call, calling success_handler
2025-05-10 03:02:13,854 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 03:02:13,858 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 03:02:13,925 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 03:02:13,980 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 03:02:15,499 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-10 03:02:26,502 INFO:HTTP Request: POST http://192.168.0.177:11434/api/generate "HTTP/1.1 200 OK"
2025-05-10 03:02:26,508 INFO:Wrapper: Completed Call, calling success_handler
2025-05-10 03:02:26,582 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 03:02:26,649 INFO:HTTP Request: POST http://192.168.0.177:11434/api/show "HTTP/1.1 200 OK"
2025-05-10 03:02:28,108 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-10 03:02:42,221 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - [WinError 10054] An existing connection was forcibly closed by the remote host
2025-05-10 03:02:42,554 INFO:127.0.0.1 - - [10/May/2025 03:02:42] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 04:51:36,735 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - [WinError 10054] An existing connection was forcibly closed by the remote host
2025-05-10 04:51:36,757 ERROR:Error processing activity: cannot schedule new futures after interpreter shutdown
Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 174, in run_pipeline
    return await self._middleware.receive_activity_with_status(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 69, in receive_activity_with_status
    return await self.receive_activity_internal(context, callback)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\middleware_set.py", line 79, in receive_activity_internal
    return await callback(context)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\activity_handler.py", line 70, in on_turn
    await self.on_message_activity(turn_context)
  File "D:\Teams-Integration\teams-aws-bot\bot\teams_bot.py", line 408, in on_message_activity
    await turn_context.send_activity(response)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 69, in messages
    response = await adapter.process_activity(activity, auth_header, bot.on_turn)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 445, in process_activity
    return await self.process_activity_with_identity(activity, identity, logic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 487, in process_activity_with_identity
    await self.run_pipeline(context, logic)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_adapter.py", line 179, in run_pipeline
    await self.on_turn_error(context, error)
  File "D:\Teams-Integration\teams-aws-bot\app.py", line 50, in on_error
    await context.send_activity("Sorry, something went wrong processing your request.")
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 174, in send_activity
    result = await self.send_activities([activity_or_text])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 226, in send_activities
    return await self._emit(self._on_send_activities, output, logic())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 304, in _emit
    return await logic
           ^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\turn_context.py", line 221, in logic
    responses = await self.adapter.send_activities(self, output)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 728, in send_activities
    raise error
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botbuilder\core\bot_framework_adapter.py", line 713, in send_activities
    response = await client.conversations.reply_to_activity(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\botframework\connector\aio\operations_async\_conversations_operations_async.py", line 524, in reply_to_activity
    response = await self._client.async_send(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\async_client.py", line 115, in async_send
    pipeline_response = await self.config.pipeline.run(request, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 159, in run
    return await first_node.send(pipeline_request, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 106, in send
    return await self.next.send(request, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_abc.py", line 79, in send
    response = await self.next.send(request, **kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\pipeline\async_requests.py", line 85, in send
    await self.driver.send(request.http_request, **kwargs)
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 91, in send
    return await super(AsyncRequestsHTTPSender, self).send(request, **requests_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Teams-Integration\teams-aws-bot\venv\Lib\site-packages\msrest\universal_http\async_requests.py", line 67, in send
    future = loop.run_in_executor(
             ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 830, in run_in_executor
    executor.submit(func, *args), loop=self)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Samriddha\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 169, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
2025-05-10 04:51:39,593 INFO:127.0.0.1 - - [10/May/2025 04:51:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 500 -
2025-05-10 15:11:16,336 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 15:11:16,338 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 15:11:16,344 INFO: * Restarting with stat
2025-05-10 15:11:33,417 WARNING: * Debugger is active!
2025-05-10 15:11:33,458 INFO: * Debugger PIN: 379-540-163
2025-05-10 15:11:42,445 INFO:127.0.0.1 - - [10/May/2025 15:11:42] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 15:13:09,699 INFO:[UserMessage] Received: attach policy
2025-05-10 15:13:12,069 INFO:127.0.0.1 - - [10/May/2025 15:13:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:21:14,646 INFO:127.0.0.1 - - [10/May/2025 16:21:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:21:28,281 INFO:[UserMessage] Received: attach policy
2025-05-10 16:21:30,617 INFO:127.0.0.1 - - [10/May/2025 16:21:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:22:11,989 INFO:127.0.0.1 - - [10/May/2025 16:22:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:29:23,052 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-10 16:29:25,485 INFO: * Restarting with stat
2025-05-10 16:29:52,628 WARNING: * Debugger is active!
2025-05-10 16:29:52,635 INFO: * Debugger PIN: 379-540-163
2025-05-10 16:32:46,410 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\aws_crew_tools\\iam.py', reloading
2025-05-10 16:32:47,898 INFO: * Restarting with stat
2025-05-10 16:33:05,268 WARNING: * Debugger is active!
2025-05-10 16:33:05,277 INFO: * Debugger PIN: 379-540-163
2025-05-10 16:36:33,200 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-10 16:36:34,943 INFO: * Restarting with stat
2025-05-10 16:36:52,129 WARNING: * Debugger is active!
2025-05-10 16:36:52,132 INFO: * Debugger PIN: 379-540-163
2025-05-10 16:40:04,584 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-10 16:40:05,802 INFO: * Restarting with stat
2025-05-10 16:40:23,150 WARNING: * Debugger is active!
2025-05-10 16:40:23,156 INFO: * Debugger PIN: 379-540-163
2025-05-10 16:45:33,137 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 16:45:33,137 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 16:45:33,137 INFO: * Restarting with stat
2025-05-10 16:45:50,095 WARNING: * Debugger is active!
2025-05-10 16:45:50,105 INFO: * Debugger PIN: 379-540-163
2025-05-10 16:46:01,097 INFO:127.0.0.1 - - [10/May/2025 16:46:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:46:11,440 INFO:[UserMessage] Received: attach policy
2025-05-10 16:46:13,785 INFO:127.0.0.1 - - [10/May/2025 16:46:13] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:46:25,080 INFO:127.0.0.1 - - [10/May/2025 16:46:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:46:54,884 INFO:[UserMessage] Received: detach policy
2025-05-10 16:46:55,804 INFO:127.0.0.1 - - [10/May/2025 16:46:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:47:08,900 INFO:127.0.0.1 - - [10/May/2025 16:47:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:50:11,453 INFO:127.0.0.1 - - [10/May/2025 16:50:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:50:27,828 INFO:127.0.0.1 - - [10/May/2025 16:50:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:50:39,900 INFO:127.0.0.1 - - [10/May/2025 16:50:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:56:01,833 INFO:127.0.0.1 - - [10/May/2025 16:56:01] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 16:56:10,674 INFO:[UserMessage] Received: attach policy
2025-05-10 16:56:12,636 INFO:127.0.0.1 - - [10/May/2025 16:56:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:22:00,172 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 17:22:00,172 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 17:22:00,176 INFO: * Restarting with stat
2025-05-10 17:22:08,548 WARNING: * Debugger is active!
2025-05-10 17:22:08,551 INFO: * Debugger PIN: 379-540-163
2025-05-10 17:22:19,731 INFO:127.0.0.1 - - [10/May/2025 17:22:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:22:23,199 INFO:[UserMessage] Received: attach policy
2025-05-10 17:22:26,641 INFO:127.0.0.1 - - [10/May/2025 17:22:26] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:29:00,527 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\adaptive_cards.py', reloading
2025-05-10 17:29:01,526 INFO: * Restarting with stat
2025-05-10 17:29:12,055 WARNING: * Debugger is active!
2025-05-10 17:29:12,055 INFO: * Debugger PIN: 379-540-163
2025-05-10 17:33:35,676 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-10 17:33:36,413 INFO: * Restarting with stat
2025-05-10 17:34:38,782 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 17:34:38,782 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 17:34:38,783 INFO: * Restarting with stat
2025-05-10 17:34:47,016 WARNING: * Debugger is active!
2025-05-10 17:34:47,018 INFO: * Debugger PIN: 379-540-163
2025-05-10 17:34:55,646 INFO:127.0.0.1 - - [10/May/2025 17:34:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:35:03,479 INFO:[UserMessage] Received: attach policy
2025-05-10 17:35:05,434 INFO:127.0.0.1 - - [10/May/2025 17:35:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:44:26,204 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 17:44:26,204 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 17:44:26,206 INFO: * Restarting with stat
2025-05-10 17:44:34,671 WARNING: * Debugger is active!
2025-05-10 17:44:34,672 INFO: * Debugger PIN: 379-540-163
2025-05-10 17:44:53,969 INFO:127.0.0.1 - - [10/May/2025 17:44:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:44:59,419 INFO:[UserMessage] Received: attach policy
2025-05-10 17:45:02,341 INFO:127.0.0.1 - - [10/May/2025 17:45:02] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:45:55,951 INFO:127.0.0.1 - - [10/May/2025 17:45:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:48:44,744 INFO:[UserMessage] Received: mfa
2025-05-10 17:48:44,995 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-10 17:48:54,166 INFO:[UserMessage] Received: enable mfa
2025-05-10 17:48:56,056 INFO:127.0.0.1 - - [10/May/2025 17:48:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:49:29,920 INFO:127.0.0.1 - - [10/May/2025 17:49:29] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 17:58:45,773 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out after 600.0 seconds.
2025-05-10 17:58:46,116 INFO:127.0.0.1 - - [10/May/2025 17:58:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:35:44,205 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 18:35:44,205 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 18:35:44,205 INFO: * Restarting with stat
2025-05-10 18:35:52,771 WARNING: * Debugger is active!
2025-05-10 18:35:52,775 INFO: * Debugger PIN: 379-540-163
2025-05-10 18:36:10,183 INFO:127.0.0.1 - - [10/May/2025 18:36:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:36:15,160 INFO:[UserMessage] Received: enable mfa
2025-05-10 18:36:17,097 INFO:127.0.0.1 - - [10/May/2025 18:36:17] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:36:22,901 INFO:127.0.0.1 - - [10/May/2025 18:36:22] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:36:55,229 INFO:127.0.0.1 - - [10/May/2025 18:36:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:37:01,886 INFO:[UserMessage] Received: create user
2025-05-10 18:37:02,248 INFO:127.0.0.1 - - [10/May/2025 18:37:02] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:37:08,492 INFO:[UserMessage] Received: create iam user
2025-05-10 18:37:08,803 INFO:127.0.0.1 - - [10/May/2025 18:37:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:37:24,113 INFO:127.0.0.1 - - [10/May/2025 18:37:24] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:37:32,452 INFO:[UserMessage] Received: enable mfa
2025-05-10 18:37:33,361 INFO:127.0.0.1 - - [10/May/2025 18:37:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:37:37,926 INFO:127.0.0.1 - - [10/May/2025 18:37:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:40:55,419 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 18:40:55,419 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 18:40:55,426 INFO: * Restarting with stat
2025-05-10 18:41:12,110 WARNING: * Debugger is active!
2025-05-10 18:41:12,115 INFO: * Debugger PIN: 379-540-163
2025-05-10 18:41:19,348 INFO:127.0.0.1 - - [10/May/2025 18:41:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:41:26,079 INFO:[UserMessage] Received: enable mfa
2025-05-10 18:41:30,529 INFO:127.0.0.1 - - [10/May/2025 18:41:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:41:35,718 INFO:127.0.0.1 - - [10/May/2025 18:41:35] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:51:32,334 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 18:51:32,334 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 18:51:32,334 INFO: * Restarting with stat
2025-05-10 18:51:48,569 WARNING: * Debugger is active!
2025-05-10 18:51:48,569 INFO: * Debugger PIN: 379-540-163
2025-05-10 18:53:14,855 INFO:[UserMessage] Received: enable mfa
2025-05-10 18:53:19,080 INFO:127.0.0.1 - - [10/May/2025 18:53:19] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:53:25,504 INFO:127.0.0.1 - - [10/May/2025 18:53:25] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 18:53:30,245 INFO:127.0.0.1 - - [10/May/2025 18:53:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:04:37,088 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 19:04:37,088 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 19:04:37,088 INFO: * Restarting with stat
2025-05-10 19:04:54,630 WARNING: * Debugger is active!
2025-05-10 19:04:54,638 INFO: * Debugger PIN: 379-540-163
2025-05-10 19:05:01,482 INFO:[UserMessage] Received: enable mfa
2025-05-10 19:05:05,456 INFO:127.0.0.1 - - [10/May/2025 19:05:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:05:12,614 INFO:127.0.0.1 - - [10/May/2025 19:05:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:36:09,473 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 19:36:09,475 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 19:36:09,481 INFO: * Restarting with stat
2025-05-10 19:36:27,202 WARNING: * Debugger is active!
2025-05-10 19:36:27,211 INFO: * Debugger PIN: 379-540-163
2025-05-10 19:38:11,079 INFO:[UserMessage] Received: enable mfa
2025-05-10 19:38:15,305 INFO:127.0.0.1 - - [10/May/2025 19:38:15] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:38:21,486 INFO:127.0.0.1 - - [10/May/2025 19:38:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:38:27,194 INFO:127.0.0.1 - - [10/May/2025 19:38:27] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:39:53,566 INFO:127.0.0.1 - - [10/May/2025 19:39:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:43:52,304 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 19:43:52,307 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 19:43:52,311 INFO: * Restarting with stat
2025-05-10 19:44:10,061 WARNING: * Debugger is active!
2025-05-10 19:44:10,066 INFO: * Debugger PIN: 379-540-163
2025-05-10 19:44:15,390 INFO:[UserMessage] Received: enable mfa
2025-05-10 19:44:20,333 INFO:127.0.0.1 - - [10/May/2025 19:44:20] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:44:30,809 INFO:127.0.0.1 - - [10/May/2025 19:44:30] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:51:58,675 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 19:51:58,675 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 19:51:58,680 INFO: * Restarting with stat
2025-05-10 19:52:15,348 WARNING: * Debugger is active!
2025-05-10 19:52:15,381 INFO: * Debugger PIN: 379-540-163
2025-05-10 19:52:28,055 INFO:[UserMessage] Received: enable mfa
2025-05-10 19:52:33,136 INFO:127.0.0.1 - - [10/May/2025 19:52:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:52:41,940 INFO:127.0.0.1 - - [10/May/2025 19:52:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:52:53,417 INFO:127.0.0.1 - - [10/May/2025 19:52:53] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:54:06,836 INFO:127.0.0.1 - - [10/May/2025 19:54:06] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 19:57:57,983 INFO: * Detected change in 'D:\\Teams-Integration\\teams-aws-bot\\bot\\teams_bot.py', reloading
2025-05-10 19:57:59,503 INFO: * Restarting with stat
2025-05-10 19:58:19,225 WARNING: * Debugger is active!
2025-05-10 19:58:19,233 INFO: * Debugger PIN: 379-540-163
2025-05-10 20:04:59,129 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 20:04:59,129 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 20:04:59,132 INFO: * Restarting with stat
2025-05-10 20:05:16,124 WARNING: * Debugger is active!
2025-05-10 20:05:16,133 INFO: * Debugger PIN: 379-540-163
2025-05-10 20:05:18,234 INFO:[UserMessage] Received: enable mfa
2025-05-10 20:05:22,849 INFO:127.0.0.1 - - [10/May/2025 20:05:22] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:05:31,144 INFO:127.0.0.1 - - [10/May/2025 20:05:31] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:19:26,147 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 20:19:26,147 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 20:19:26,153 INFO: * Restarting with stat
2025-05-10 20:19:44,341 WARNING: * Debugger is active!
2025-05-10 20:19:44,341 INFO: * Debugger PIN: 379-540-163
2025-05-10 20:19:45,436 INFO:[UserMessage] Received: create user
2025-05-10 20:19:47,927 INFO:127.0.0.1 - - [10/May/2025 20:19:47] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:19:55,410 INFO:[UserMessage] Received: create iam user
2025-05-10 20:19:55,808 INFO:127.0.0.1 - - [10/May/2025 20:19:55] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:20:08,931 INFO:127.0.0.1 - - [10/May/2025 20:20:08] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:20:11,305 INFO:[UserMessage] Received: enable mfa
2025-05-10 20:20:12,221 INFO:127.0.0.1 - - [10/May/2025 20:20:12] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:20:21,724 INFO:127.0.0.1 - - [10/May/2025 20:20:21] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:21:41,342 INFO:127.0.0.1 - - [10/May/2025 20:21:41] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:21:56,181 INFO:127.0.0.1 - - [10/May/2025 20:21:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:28:41,396 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 20:28:41,396 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 20:28:41,398 INFO: * Restarting with stat
2025-05-10 20:28:52,487 WARNING: * Debugger is active!
2025-05-10 20:28:52,493 INFO: * Debugger PIN: 379-540-163
2025-05-10 20:28:53,292 INFO:[UserMessage] Received: create iam user
2025-05-10 20:28:56,196 INFO:127.0.0.1 - - [10/May/2025 20:28:56] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:29:05,692 INFO:127.0.0.1 - - [10/May/2025 20:29:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:29:10,002 INFO:[UserMessage] Received: enable mfa
2025-05-10 20:29:10,918 INFO:127.0.0.1 - - [10/May/2025 20:29:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:29:18,450 INFO:127.0.0.1 - - [10/May/2025 20:29:18] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:30:07,993 INFO:127.0.0.1 - - [10/May/2025 20:30:07] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:39:03,008 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 20:39:03,008 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 20:39:03,010 INFO: * Restarting with stat
2025-05-10 20:39:11,458 WARNING: * Debugger is active!
2025-05-10 20:39:11,458 INFO: * Debugger PIN: 379-540-163
2025-05-10 20:39:31,898 INFO:[UserMessage] Received: create iam user
2025-05-10 20:39:33,945 INFO:127.0.0.1 - - [10/May/2025 20:39:33] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:39:46,147 INFO:127.0.0.1 - - [10/May/2025 20:39:46] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:39:58,690 INFO:[UserMessage] Received: enable mfa
2025-05-10 20:39:59,580 INFO:127.0.0.1 - - [10/May/2025 20:39:59] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:40:09,521 INFO:127.0.0.1 - - [10/May/2025 20:40:09] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:40:37,419 INFO:127.0.0.1 - - [10/May/2025 20:40:37] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:41:05,338 INFO:127.0.0.1 - - [10/May/2025 20:41:05] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:41:29,342 INFO:127.0.0.1 - - [10/May/2025 20:41:29] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:41:39,339 INFO:127.0.0.1 - - [10/May/2025 20:41:39] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:42:11,269 INFO:127.0.0.1 - - [10/May/2025 20:42:11] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 20:44:09,407 INFO:[UserMessage] Received: aws means
2025-05-10 20:44:09,465 INFO:
LiteLLM completion() model= llama3:latest; provider = ollama
2025-05-10 20:54:09,770 ERROR:LiteLLM call failed: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out after 600.0 seconds.
2025-05-10 20:54:10,120 INFO:127.0.0.1 - - [10/May/2025 20:54:10] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 21:13:35,710 INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3978
 * Running on http://192.168.0.119:3978
2025-05-10 21:13:35,710 INFO:[33mPress CTRL+C to quit[0m
2025-05-10 21:13:35,714 INFO: * Restarting with stat
2025-05-10 21:13:44,133 WARNING: * Debugger is active!
2025-05-10 21:13:44,143 INFO: * Debugger PIN: 379-540-163
2025-05-10 21:14:11,967 INFO:[UserMessage] Received: create iam user
2025-05-10 21:14:14,612 INFO:127.0.0.1 - - [10/May/2025 21:14:14] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 21:14:24,442 INFO:127.0.0.1 - - [10/May/2025 21:14:24] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 21:14:31,072 INFO:[UserMessage] Received: enable mfa
2025-05-10 21:14:31,961 INFO:127.0.0.1 - - [10/May/2025 21:14:31] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 21:14:42,117 INFO:127.0.0.1 - - [10/May/2025 21:14:42] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
2025-05-10 21:15:40,656 INFO:127.0.0.1 - - [10/May/2025 21:15:40] "[35m[1mPOST /api/messages HTTP/1.1[0m" 201 -
